<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">

<HTML>
<HEAD>
<TITLE> C-DAC,Pune : High-Perf. Comp. Frontier Technologies Exploration Group and
 CMSD, University of Hyderabad, Technology Workshop hyPACK (October 15-18), 2013 </TITLE>

<META http-equiv=Content-Type content="text/html; charset=iso-8859-1">

<meta name="Description" content="Center for Development of Advanced Computing (C-DAC) Pune and 

   Centre for Modelling Simulation and Design (CMSD), High-Performance Computing (HPC) Facility
   University of Hyderabad, Hyderabad are jointly organizing four days technology 
   workshop on   Hybrid Computing - Coprocessors &amp; Accelerators - 
   Power-aware Computing &amp;  Performance of  
  Application Kernels (HyPACK-2013)
  (Initiatives on Measurement Power Consumption &amp; Performance of Kernels"
    which is scheduled from October 15-18, 2013 at CMSD,
   High-Performance Computing (HPC) facility University of 
  Hyderabad, Hyderabad.The hyPACK-2013 is designed four days for HPC GPU Cluster
 for Applications."/>

<meta name="KeyWords" content="Multi-Core, Parallel Processing,
 Software threading,GPGPU,GPU computing,MPI,OpenCL, Intel Xeon Phi-Co-processor, 
 NVIDIA -CUDA,AMD-APP Computing, Intel MIC, C-DAC workshops,OpenMP,Pthreads,Heterogenous  Computing,Multi-Core tools,MultiCore 
 Processors,GPU Programming, OpenMP 4.0, HPC GPU Cluster, 
 Performance CDAC Technology training programme(S),Intel Software tools" />

<META id=Copyright content="Copyright (c) 2013,C-DAC." name=Copyright>

<META http-equiv=imagetoolbar content=no>

<LINK href="./../../hypack13-files/hypack-main.css" type=text/css rel=stylesheet>
<LINK href="./../../hypack13-files/hypack-home.css" type=text/css rel=stylesheet>
<LINK href="./../../hypack13-files/hypack-schedule.css" rel=stylesheet>

<SCRIPT language=JavaScript src="./../../hypack13-files/hypack-main.js" type=text/javascript></SCRIPT>

<META content="MSHTML 6.00.2900.5726" name=GENERATOR>

</HEAD>

<BODY style="MARGIN: 0px" leftMargin=0 topMargin=0 marginheight="0" marginwidth="0">

<TABLE class=container cellSpacing=0 cellPadding=0 border=0>
  <TBODY>
  <TR>
    <TD class=container>
      <TABLE class=header cellSpacing=0 cellPadding=0 border=0>
        <TBODY>
        <TR>
          <TD class=headerlogo>
                       <A href="./../../index.html">
      <IMG alt=hypack-2013 src="./../../hypack13-files/hypack-2013-header.jpg" border=0>
           </A>
       </TD>
 
     </TR>
     </TBODY>
     </TABLE>
      

<SCRIPT language=JavaScript1.2 type=text/javascript>

</SCRIPT>

     

        
  <TABLE class=mainmenubar cellSpacing=0 cellPadding=0>
        <TBODY>
        <TR>
          <TD align=middle>
            <TABLE cellSpacing=0 cellPadding=0>
              <TBODY>
 
	      <TR>

                <TD class=menu1><A class=menu1 id=mainmenurow1 
                  onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
       		  href="./../../hypack13-about-overview.html">About</A></TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow2 
                  onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
                  href="./../../hypack13-tech-prog-topics-overview.html">  Tech. Prog. </A></TD>
    
                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow3 
                  onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
                  href="./../../hypack13-mode01-multicore-lab-overview.html">Muti-Core </A></TD>
                
               <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow4 
                  onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
                  href="./../../hypack13-mode02-arm-proc-lab-overview.html"> ARM Proc</A></TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow5 
                  onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
                  href="./../../hypack13-mode03-coprocessor-lab-overview.html">Coprocessors </A></TD>
                        
     
                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow6
                  onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
                  href="./../../hypack13-mode04-gpgpu-lab-overview.html"> GPUs </A> </TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow7 
                  onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
                  href="./../../hypack13-mode05-hpc-cluster-lab-overview.html"> HPC Cluster</A></TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow6
                  onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
                  href="./../../hypack13-mode06-app-kernels-lab-overview.html"> App. Kernels</A> </TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow7 
                  onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
                  href="./../../hypack13-reg-overview.html">Registration </A></TD>

                                                          
</TR></TBODY></TABLE></TD></TR></TBODY>
	</TABLE>

      <DIV class=menu2>

 <!--   Sub menu for **** Row-1-About ****  start here -->

      <TABLE id=submenutab1 onMouseOver="javascript:hypackShowSubMenuDelay('1',1)" 
       style="VISIBILITY: hidden; MARGIN-LEFT: 0px; POSITION: absolute" 
       onmouseout="javascript:hypackHideSubMenuDelay('1',1)" cellSpacing=0 
       cellPadding=0 width=150>

       <TBODY>
       <TR>
       <TD class=menu2>


      <A class=menu2 id=submenurow1s1 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-overview.html"><B> Overview </B></A>
  
      <A class=menu2 id=submenurow1s2 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-venue.html"><B>  Venue : CMSD, UoH </B></A>

       <A class=menu2 id=submenurow1s3 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-keynote-invited-talks.html"><B>  Key-Note/Invited Talks </B> </A>

        <A class=menu2 id=submenurow1s4 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-faculty.html"><B>  Faculty / Speakers </B></A>

       <A class=menu2 id=submenurow1s5 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-proceedings.html"><B>   Proceedings </B></A>

	<A class=menu2 id=submenurow1s6 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-download-software.html"><B>  Downloads  </B> </A>
  
	<A class=menu2 id=submenurow1s7
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-past-workshops.html"><B>  Past Tech. Workshops </B></A>

       <A class=menu2 id=submenurow1s8 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-audience.html"><B> Target Audience </B></A>

       <A class=menu2 id=submenurow1s9 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-benefits.html"><B> Benefits</B></A>

	<A class=menu2 id=submenurow1s10 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-organisers.html"><B>  Organisers </B> </A>

        <A class=menu2 id=submenurow1s11 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-accommodation.html"><B>  Accommodation </B></A>

        <A class=menu2 id=submenurow1s12 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-local-travel.html"><B> Local Travel</B></A>

	<A class=menu2 id=submenurow1s13 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-sponsors.html"><B>  Sponsors </B></A>

        <A class=menu2 id=submenurow1s14 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-feedback.html"><B>  Feedback </B></A>

        <A class=menu2 id=submenurow1s15 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-acknowledgements.html"><B>  Acknowledgements </B> </A>

        <A class=menu2 id=submenurow1s16 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../hypack13-about-contact-address.html"><B>  Contact </B> </A>

        <A class=menu2 id=submenurow1s17 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="./../../index.html"><B>   Home  </B> </A>

 
      </TD></TR></TBODY></TABLE>

<!--   Sub menu for **** Row-1-About **** End  here --> 



<!--   Sub menu for **** Row-2-Topics of interest ****  start  here --> 

      <TABLE id=submenutab2 onMouseOver="javascript:hypackShowSubMenuDelay('2',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 60px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('2',1)" cellSpacing=0 
      cellPadding=0 width=150>
        <TBODY>
        <TR>
          <TD class=menu2>

          <A class=menu2 id=submenurow2s1 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-tech-prog-topics-overview.html"><B>  Topics of Interest </B></A>

          <A class=menu2 id=submenurow2s2 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-tech-prog-schedule.html"><B> Tech. Prog. Schedule</B></A>
   
	 <A class=menu2 id=submenurow2s3 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-mode01-multicore.html"><B>  Topic : Multi-Core </B></A>

         <A class=menu2 id=submenurow2s4 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-mode02-arm-proc.html"><B>  Topic : ARM Proc. </B></A>

         <A class=menu2 id=submenurow2s5 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-mode03-coprocessor.html"><B>  Topic : Coprocessors </B></A>

         <A class=menu2 id=submenurow2s6 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-mode04-gpgpu.html"><B>  Topic : GPGPUs </B></A>

         <A class=menu2 id=submenurow2s7 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-mode05-hpc-cluster.html"><B>  Topic : HPC  Cluster</B></A>

         <A class=menu2 id=submenurow2s8 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-mode06-app-kernels.html"><B>  Topic : App. Kernels.</B></A>
                    
         <A class=menu2 id=submenurow2s9
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-laboratory.html"><B>  Topic : Lab. Session</B></A>

         <A class=menu2 id=submenurow2s10 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../hypack13-topics-keynote-invited-talks.html"><B> Key-Note / Invited Talks</B> </A>

           
         <A class=menu2 id=submenurow2s11 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="./../../index.html"><B>    Home  </B> </A>
 
	
      </TD></TR></TBODY></TABLE>

<!--   Sub menu for **** Row-2-Topics of interest ***** End  here -->



<!--   Sub menu for **** Row-3 : Mode 1 (Multi-Cores): Hands-on ****  start here  -->

      <TABLE id=submenutab3 onMouseOver="javascript:hypackShowSubMenuDelay('3',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 200px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('3',1)" cellSpacing=0 
      cellPadding=0 width=150>

        <TBODY>
        <TR>
          <TD class=menu2>
        <A class=menu2 id=submenurow3s1 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-lab-overview.html"><B>   Mode-1 Multi-Core </B></A>

        <A class=menu2 id=submenurow3s2 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-memory-allocators.html"><B> Memory Allocators</B></A>

        <A class=menu2 id=submenurow3s3
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-openmp.html"><B>OpenMP  </B></A>

        <A class=menu2 id=submenurow3s4 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-intel-tbb.html"><B> Intel TBB </B></A>

        <A class=menu2 id=submenurow3s5 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-pthreads.html"><B>  Pthreads  </B></A>
	
       <A class=menu2 id=submenurow3s6 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-java-threads.html"><B> Java - Threads  </B></A>

       <A class=menu2 id=submenurow3s7 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-charmplusplus.html"><B> Charm++ Prog. </B></A>

        <A class=menu2 id=submenurow3s8
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-mpi.html"><B> Message Passing (MPI) </B></A>
 
        <A class=menu2 id=submenurow3s9
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-mpi-openmp.html"><B>  MPI - OpenMP</B></A>
  
       <A class=menu2 id=submenurow3s10
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-mpi-tbb.html"><B>  MPI - Intel TBB </B></A>
 
       <A class=menu2 id=submenurow3s11
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-mpi-pthreads.html"><B>  MPI - Pthreads </B></A>

        <A class=menu2 id=submenurow3s12 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-compiler-tune-perf.html"><B> Compilers - Opt. Features </B></A>

        <A class=menu2 id=submenurow3s13 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-perf-math-lib.html"><B> Threads-Perf. Math. Lib.</B></A>

        <A class=menu2 id=submenurow3s14 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-software-tools.html"><B>  Threads-Prof. &amp; Tools</B></A>

       <A class=menu2 id=submenurow3s15 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-threads-io-perf.html"><B>Threads - I/O Perf. </B></A>
  
        <A class=menu2 id=submenurow3s16 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-pgas-langlib.html"><B> PGAS : UPC / CAF/ GA</B></A>

        <A class=menu2 id=submenurow3s17
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../hypack13-mode01-multicore-power-perf.html"><B> Power &amp; Perf.  </B></A>

       <A class=menu2 id=submenurow3s18 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="./../../index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>

<!--   Sub menu **** Row-3 : Mode 1 (Multi-Cores ) : Hands-on ****  End here  -->



<!--   Sub menu for **** Row-4 : Mode 2 (ARM Processor) Hands-on ****  start here  -->

      <TABLE id=submenutab4 onMouseOver="javascript:hypackShowSubMenuDelay('4',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 200px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('4',1)" cellSpacing=0 
      cellPadding=0 width=150>

        <TBODY>
        <TR>
          <TD class=menu2>
        <A class=menu2 id=submenurow4s1 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="./../../hypack13-mode02-arm-proc-lab-overview.html"><B>   Mode-2 ARM  </B></A>

        <A class=menu2 id=submenurow4s2 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="./../../hypack13-mode02-arm-proc-prog-env.html"><B> Prog. Env </B></A>
      
       <A class=menu2 id=submenurow4s3 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="./../../hypack13-mode02-arm-proc-benchmarks.html"><B> Benchmarks</B></A>

       <A class=menu2 id=submenurow4s4
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="./../../hypack13-mode02-arm-proc-power-perf.html"><B> Power &amp; Perf.  </B></A>

       <A class=menu2 id=submenurow4s5 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="./../../index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>


<!--   Sub menu **** Row-4 : Mode 2 (ARM Processor) : Hands-on ****  End here  -->




<!--   Sub menu for **** Row-5 : Mode 3 (Coprocessor) Hands-on ****  start here  -->

      <TABLE id=submenutab5 onMouseOver="javascript:hypackShowSubMenuDelay('5',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 200px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('5',1)" cellSpacing=0 
      cellPadding=0 width=150>

        <TBODY>
        <TR>
          <TD class=menu2>
        <A class=menu2 id=submenurow5s1 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="./../../hypack13-mode03-coprocessor-lab-overview.html"><B>   Mode-3 Coprocessors </B></A>

        <A class=menu2 id=submenurow5s2 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="./../../hypack13-mode03-coprocessor-arch-software.html"><B> Arch. Software </B></A>

        <A class=menu2 id=submenurow5s3 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="./../../hypack13-mode03-coprocessor-compiler-vect.html"><B> Compiler &amp; Vect. </B></A>
     
        <A class=menu2 id=submenurow5s4 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="./../../hypack13-mode03-coprocessor-prog-env.html"><B> Prog. Env. </B></A>

        <A class=menu2 id=submenurow5s5 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="./../../hypack13-mode03-coprocessor-benchmarks.html"><B> Benchmarks</B></A>

        <A class=menu2 id=submenurow5s6
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="./../../hypack13-mode03-coprocessor-power-perf.html"><B> Power &amp; Perf.  </B></A>

        <A class=menu2 id=submenurow5s7 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="./../../index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>


<!--   Sub menu **** Row-5 : Mode 3 (Coprocessor) : Hands-on ****  End here  -->



<!--   Sub menu for **** Row-6 : Mode 4 (GPGPUs): Hands-on **** Start here  -->

      <TABLE id=submenutab6 onMouseOver="javascript:hypackShowSubMenuDelay('6',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 285px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('6',1)" cellSpacing=0 
      cellPadding=0 width=150>
        <TBODY>
        <TR>
          <TD class=menu2>

	<A class=menu2 id=submenurow6s1 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="./../../hypack13-mode04-gpgpu-lab-overview.html"><B> Mode-4 GPGPUs  </B></A>

	<A class=menu2 id=submenurow6s2 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="./../../hypack13-mode04-gpgpu-nvidia-gpu-cuda.html"><B>NVIDIA - CUDA/OpenCL </B></A>


	<A class=menu2 id=submenurow6s3 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="./../../hypack13-mode04-gpgpu-amd-opencl.html"><B>AMD  APP - OpenCL</B></A>


	<A class=menu2 id=submenurow6s4 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="./../../hypack13-mode04-gpgpu-opencl.html"><B> GPGPUs - OpenCL </B></A>

        <A class=menu2 id=submenurow6s5 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="./../../hypack13-mode04-gpgpu-power-perf.html"><B> GPGPUs : Power &amp; Perf. </B></A>

        <A class=menu2 id=submenurow6s6 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="./../../index.html"><B>   Home  </B> </A>


	   </TD></TR> </TBODY></TABLE>

<!--  Sub menu for **** Row-6 : Mode-4 (GPGPUs) : Hands-on **** End here  -->



<!--   Sub menu for **** Row-7 : Mode-5 (HPC GPU Cluster): Hands-on  **** start  here -->

      <TABLE id=submenutab7 onMouseOver="javascript:hypackShowSubMenuDelay('7',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 365px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('7',1)" cellSpacing=0 
      cellPadding=0 width=150>


        <TBODY>
        <TR>
          <TD class=menu2>

        <A class=menu2 id=submenurow7s1 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="./../../hypack13-mode05-hpc-cluster-lab-overview.html"><B>  Mode-5  HPC Cluster </B></A>
        
        <A class=menu2 id=submenurow7s2 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="./../../hypack13-mode05-hpc-message-passing-cluster.html"><B> HPC  MPI   Cluster   </B></A>

	<A class=menu2 id=submenurow7s3
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="./../../hypack13-mode05-hpc-gpu-cluster-nvidia-cuda.html"><B> GPU Cluster - NVIDIA   </B></A>

        <A class=menu2 id=submenurow7s4 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="./../../hypack13-mode05-hpc-gpu-cluster-amd-opencl.html"><B>GPU Cluster - AMD APP </B></A>


        <A class=menu2 id=submenurow7s5 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="./../../hypack13-mode05-hpc-intel-coprocessor-cluster.html"><B> Cluster - Intel Coprocessors </B></A>

        <A class=menu2 id=submenurow7s6 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="./../../hypack13-mode05-hpc-cluster-power-perf.html"><B>  Cluster- Power &amp; Perf.  </B> </A>

        <A class=menu2 id=submenurow7s7 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="./../../index.html"><B>  Home  </B> </A>
      
	</TD></TR>
        </TBODY>
        </TABLE>


<!--   Sub menu for **** Row-7 : MODe-5 : (HPC GPU Cluster) Hands-on ****  End  here -->



<!--   Sub menu for **** Row-8 :Mode-6 Application  program  **** start here -->


      <TABLE id=submenutab8 onMouseOver="javascript:hypackShowSubMenuDelay('8',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 510px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('8',1)" cellSpacing=0 
      cellPadding=0 width=150>
        <TBODY>
        <TR>
          <TD class=menu2>
 
	 <A class=menu2 id=submenurow8s1 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-app-kernels-lab-overview.html"><B> Mode-6 App. Kernels </B></A>
                  
	<A class=menu2 id=submenurow8s2 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-pdesolvers-fdm-fem.html"><B>  PDE Solvers : FDM/FEM  </B></A>

        <A class=menu2 id=submenurow8s3 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-image-processing-fft.html"><B>  Image Processing - FFT </B></A>    

         <A class=menu2 id=submenurow8s4
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-phys-monte-carlo.html"><B> Monte Carlo Methods </B> </A>

     	 <A class=menu2 id=submenurow8s5 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-string-srch.html"><B>  String Srch. </B></A>
    

     	 <A class=menu2 id=submenurow8s6 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-seq-analysis.html"><B>  Seq. Analy.</B></A>
       
         <A class=menu2 id=submenurow8s7
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-video-processing.html"><B> Video Process. </B> </A>

        <A class=menu2 id=submenurow8s8 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-intrusion-detection-sys.html"><B>  Intr. Detcn. Sys  </B> </A>

        <A class=menu2 id=submenurow8s9 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../hypack13-mode06-app-kernels-power-perf.html"><B>  App. Power &amp; Perf.  </B> </A>

        <A class=menu2 id=submenurow8s10 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="./../../index.html"><B>   Home  </B> </A>


       </TD></TR></TBODY></TABLE>

<!--   Sub menu for **** Row-8 :Mode-6 Application Program **** End here -->


<!--  Sub menu for **** Row-9-Registration **** Start here  -->

      <TABLE id=submenutab9 onMouseOver="javascript:hypackShowSubMenuDelay('9',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 610px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('9',1)" cellSpacing=0 
      cellPadding=0 width=150>

      <TBODY>
      <TR>
      <TD class=menu2>

      <A class=menu2 id=submenurow9s1 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../hypack13-reg-overview.html"><B> Reg. Overview</B></A>
           
      <A class=menu2 id=submenurow9s2 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../hypack13-reg-private-sector.html"><B>Pvt. Sector</B></A>

      <A class=menu2 id=submenurow9s3 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../hypack13-reg-govt-public-sector.html"><B>Pub. Sector</B></A>

      <A class=menu2 id=submenurow9s4 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../hypack13-reg-govt-academic-staff.html"><B>Govt. Acad. Staff </B></A>

      <A class=menu2 id=submenurow9s5 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../hypack13-reg-students.html"><B>Students Reg. </B></A>

      <A class=menu2 id=submenurow9s6
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../hypack13-reg-online-registration.html"><B>On-line Reg.</B></A>
 
      <A class=menu2 id=submenurow9s7 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
             href="./../../hypack13-reg-accommodation.html"><B>Accommodation </B></A>

      <A class=menu2 id=submenurow9s8 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../hypack13-reg-contact-address.html"><B>Contact</B></A>

       <A class=menu2 id=submenurow9s9 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="./../../index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>

  <!--   Sub menu for  **** Row-9-Registration **** End here  -->

  </DIV>
    

<!--********** left section code for about link start here**************** -->


	<INPUT id=menuval 
      type=hidden name=menuval> <INPUT id=menuval2 type=hidden name=menuval2> 
      <TABLE class=mainctnt cellSpacing=0 cellPadding=0 border=0>
        <TBODY>
        <TR>
          <TD class=mainctntcell>
            <TABLE cellSpacing=0 cellPadding=0 border=0>
              <TBODY>
              <TR>
                <TD class=leftmenu><BR>
			
               <A class=menul
		  href="./../../hypack13-mode04-gpgpu-lab-overview.html">
                  . Mode-4 GPGPUs </A>
                  
	          <!-- ** -->
                  <A class=menulslct
                    href="./../../hypack13-mode04-gpgpu-nvidia-gpu-cuda.html">
                    .  NVIDIA - CUDA/OpenCL</A>
                  <!-- ** -->
              
	       <A class=menul  
                  href="./../../hypack13-mode04-gpgpu-amd-opencl.html">
                  . AMD APP  OpenCL </A>
                             
	       <A class=menul  
                   href="./../../hypack13-mode04-gpgpu-opencl.html">
                   . GPGPUs - OpenCL</A>

	       <A class=menul  
                   href="./../../hypack13-mode04-gpgpu-power-perf.html">
                   . GPGPUs : Power &amp; Perf.</A>
               
               <A class=menul 
	           href="./../../index.html">
                   . Home</A>
       
 <!-- *********left section code for about link End  here *************-->
	
      <BR>
       <DIV 
          style="BACKGROUND: url(images/) no-repeat 100% 100%; WIDTH: auto; HEIGHT: 300px">
       </DIV><BR><BR><BR><BR></TD>
                
 <TD class=rightctnt> 

<!--  content of web page start here  --> 

<TABLE cellSpacing=0 cellPadding=0 border=0>
<TBODY>

<!--  content of web page start here  --> 


<TR>
<TD>


<TABLE cellPadding=3  border=0> 
<TBODY>
<TR> 

<TD bgColor = "#cccdd77889"> 
 <DIV align=left><font size="2"  Color="black" face= "verdana">
    <B>   hyPACK-2013 Mode-2 : GPU Comp. CUDA enabled NVIDIA GPU Prog.  </b> </font></DIV> </TD> </TR> 

  <tr>
    <td height="24" align="left" >

 <P align=justify> <span class="content">

NVIDIA\92s
Compute Unified Device Architecture (CUDA) is a soft-
ware platform for massively parallel high-performance
computing on the company's powerful GPUs.  NVIDIA\92s  software CUDA programming model effectively use GPUs which could be 
harnessed for tasks other than 
graphics, achieving teraflops of computing power.  

CUDA Programming model automatically manages the threads and it is significantly differs from single 
threaded CPU code and to some extent even the parallel code.  Efficient CUDA programs exploit both 
thread parallelism within a thread block and coarser block parallelism across thread blocks. Because only 
threads within the same block can cooperate via shared memory and thread synchronization, programmers 
must partition computation into multiple blocks. 

</span> </p>
</td> </tr> 
</tbody>
</table>

<!-- *************** Table for Listing of Programs Starts  ****************** -->
<BR>

<TABLE cellPadding=3  border=0> 
<TBODY>

 <font size="2" face="Arial" color="red"> <b> List of  Programs </b> </font> </p>

 <!--************* Example 2.1 : starts ***************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id21">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.1 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top"> 
       <span class = "content">
         Simple test  Programs using  CUBLAS1, CUBLAS2, CBLAS3 library function calls. 
       </span>
     </td>

   </tr>
 <!-- ***************** Example 2.1 : ends ***************** -->


 <!--************* Example 2.2 : starts ***************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id22">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.2 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top"> 
       <span class = "content">
         Write a Program for vector vector multiplication using CUBLAS1 library function calls. 
       </span>
     </td>

   </tr>
 <!-- ***************** Example 2.2 : ends ***************** -->

 <!-- ************* Example 2.3 : starts ************ -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id23">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.3 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top"> 
         <span class = "content">
         Write a Program for multiplication of a scalar with a  vector  and add the resultant vector 
        to  a vector using CUBLAS1 library  function calls.
       </span> 
     </td>

   </tr>
 <!-- ***************** Example 2.3 : ends **************** -->

 <!-- **************** Example 2.4 : starts ************* -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id24">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.4 </b> </font> <BR>
       </a>  
      </td>
   
      <td width="680" height="2" valign="top"> 
         <span class = "content"> 
 Write a Program for Matrix Vector multiplication using CUBLAS2 library function calls. 
 
        </span>
     </td>

   </tr>
 <!--************ Example 2.4 : ends ************* -->

 <!--*********** Example 2.5 : starts ************ -->
    <tr>
     <td width="120" height="2" valign="top">  
       <a href="#cuda-prog-number-id25">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.5 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top"> 
      <span class = "content">
         Write a Program for Matrix Matrix multiplication using CUBLAS3 library function calls.
        
      </span> 
     </td>

   </tr>
 <!-- **************** Example 2.5 : ends ****************** -->


 
<!--*********** Example 2.6 : starts ************ -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id26">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.6 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top"> 
         <span class = "content">
         Write a CUBLAS CUDA Program for  implement solution of matrix system of linear 
      equations <B>Ax = b </B> by Jacobi method.

       </span> 
     </td>

   </tr>
 <!-- **************** Example 2.6 : ends ****************** -->

<!-- *************** Example 2.7 : starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id27">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.7 </b> </font>  
       </a>  
      </td>
   
      <td width="700" height="2" valign="top"> 
       <span class = "content">
         Write a CUBLAS CUDA program to implement the  soluiton of Matrix system of Linear Equations 
            <B> AX=b </b>  by Conjugate Gradient method (Iterative Method). 
       </span> 
     </td>

   </tr>
 <!-- ************ Example 2.7 : ends ************ -->

<!-- *************** Example 2.8: starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id28">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.8 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top">
         <span class = "content">
         Write a CUBLAS CUDA program on sparse matrix multiplication of size n x n and vector of size n.(Assignment)
        </span> 
     </td>

   </tr>
 <!-- ************ Example 2.8 : ends ************ -->


<!-- *************** Example 2.9: starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id29">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.9 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top">
         <span class = "content">
         Write a CUDA program for matrix into matrix multiplication using vendour supplied BLAS libraries (DGEMM)
         on host-CPU &amp; Device-GPU to perform computations on host-CPU &amp; device-GPU and extract performance 
         in Gigaflops 
        </span> 
     </td>

   </tr>
 <!-- ************ Example 2.9 : ends ************ -->

<!-- *************** Example 2.10: starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id210">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.10 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top">
         <span class = "content">
         Write a CUDA program for matrix into matrix multiplication using vendour supplied CUDA BLAS libraries (DGEMM)
         and extract the performance in terms of Gflops.
         
        </span> 
     </td>

   </tr>
 <!-- ************ Example 2.10 : ends ************ -->



<!-- *************** Example 2.11: starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id211">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.11 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top">
         <span class = "content">
         
         Write a CUDA program to Demonstrate the Performance of Matrix Matrix Multiplication and extract the performance in terms of Gflops.
        </span> 
     </td>

   </tr>
 <!-- ************ Example 2.11 : ends ************ -->

<!-- *************** Example 2.12: starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id213">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.12 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top">
         <span class = "content">
         Demonstrate performance of matrix and vector computations on NVIDIA GPUs using MAGAMA BLAS library functions.
<font color="red">(Assignment) </font>
         
        </span> 
     </td>

   </tr>
 <!-- ************ Example 2.12 : ends ************ -->

<!-- *************** Example 2.13: starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id214">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.13</b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top">
         <span class = "content">
         Demonstrate performance of  data-parallel algorithm primitives such 
as parallel prefix-sum (\93scan\94), parallel sort and parallel 
reduction
using CUDPP Library. 
<font color="red">(Assignment) </font>
         
        </span> 
     </td>

   </tr>
 <!-- ************ Example 2.13 : ends ************ -->

<!-- *************** Example 2.14: starts ****************** -->
    <tr>
     <td width="120" height="2" valign="top"> 
       <a href="#cuda-prog-number-id215">
         <font size="2" face="Arial" color="blue">
            <b>  Example 2.14 </b> </font> 
       </a>  
      </td>
   
      <td width="680" height="2" valign="top">
         <span class = "content">
         Demonstrate performance of sparse matrices computation using  NVIDIA CUDA CUSPARSE library.
<font color="red">(Assignment) </font>
         
        </span> 
     </td>

   </tr>
 <!-- ************ Example 2.14 : ends ************ -->


<!-- ************ bullet for going to top of the page : starts *************** -->

<TR>
<TD> </TD>
<TD>

 <DIV ALIGN=right>
        <A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A> 
        </DIV>
<br>
</td>
</tr>
 <!--************** bullet for going to top of the page : ends *****************-->


</TBODY> 
</TABLE> 

<HR> 

<!-- ************ Table for Listing of Programs Ends ********************** -->

<TABLE cellPadding=3 width = " 100% "  border=0> 
<TBODY>

<TR> 
<TD bgColor = "#cccdd77889"> 
                    <DIV align=Left><font size="2" font Color="black" face= "verdana">
     <B>  Programs for Matrix Computations using AMD-APP Lib. </b> </font></DIV>  
</TD> 
<Br> 
</TR> 

</tbody>
</table>


<!-- ********************** Make file  starts *********************** -->


<table border="0" height="6">
<tbody>

  <tr>
   <td width="15%" height="2" align="left">
      <b>  <font color = "red"> Makefile </font>   </b> 
     </td>

   <td width="85%" height="2" align="left">
      To Compile the program 
    
   <!-- **************** download  Starts here **************** -->
  
   (Download source code : <BR>
   <I>
   <a href="../gpu-comp-nvidia-cuda-num-library-codes/Makefile-cublase">
   <font color ="blue">Makefile-cublase </font> </a> 

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/Makefile-cublas">
  <font color ="blue"> Makefile-cublas </font> </a>) 
  </I>
   <!-- *************** download  Ends here ************* -->

 </td>

 </tr> 
</tbody>
</table>
<br>
<!-- ********************** Make file  ends *********************** -->


<!-- ********************** example 2.1 starts *********************** -->

<a name="cuda-prog-number-id21"> </a>


<table border="0" height="6">
<tbody>

   <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.1:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
     Write a Program for vector vector multiplication using CUBLAS1 library function calls. 

 
 <!-- **************** download  Starts here **************** -->
<BR> 
(Download source code : 
<I>


  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CudaBlas_Lib/cuda_blas1.c">
   <font color ="blue"> cuda_blas1 </font> </a>
   &nbsp; 
 
  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CudaBlas_Lib/cuda_blas2.c">
   <font color ="blue"> cuda_blas2.c </font> </a> 
  &nbsp;  

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CudaBlas_Lib/cuda_blas3.c">
   <font color ="blue"> cuda_blas3.c </font> </a>) &nbsp; &nbsp;
  </I>

 <BR> <BR> 

(Download CUBLAS test  codes : 
<I>

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CudaBlas_Lib/test_cublas1.c">
   <font color ="blue"> test_cublas1.c </font> </a>
   &nbsp; 
 
  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CudaBlas_Lib/test_cublas2.c">
   <font color ="blue"> test_cublas1.c </font> </a> 
  &nbsp;  

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CudaBlas_Lib/test_cublas3.c">
   <font color ="blue"> test_cublas1.c </font> </a>) &nbsp; &nbsp;
  </I>
 <BR> 

( Download  WinRAR ZIP archive: <BR>
<I>
 
<a href="../gpu-comp-nvidia-cuda-num-library-codes/CudaBlas_Lib.zip">
 <font color ="blue"> CudaBlas_Lib (WinRAR ZIP archive)</font> 
</a> </I>)




<!-- *************** download  Ends here ************* -->

 </td>
 </tr> 
</tbody>
</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>

<LI><B> Objective </B>

<font size="2">
<P>  Write test programs using CUBLAS1, CUBLAS2, CUBLAS3 library function calls 
 (CudaBlas Library \96 wrapper functions for efficient and simple usage of CUBLAS <br>

</P>
</LI>
</uL>

<br>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>


</TD>
</tr>
</tbody>
</table>

<!-- ************************* example 2.1 ends **************************** -->


<!-- ********************** example 2.2 starts *********************** -->

<a name="cuda-prog-number-id22"> </a>


<table border="0" height="6">
<tbody>

   <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.2:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
     Write a Program for vector vector multiplication using CUBLAS1 library function calls. 

 
 <!-- **************** download  Starts here **************** -->
<BR> 
(Download source code : 
<I>

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CUBlasSVectVectMult.cu">

  <font color ="blue"> CUBlasSVectVectMult.cu) </font>
  </a>
  </I>
&nbsp;  &nbsp;


<!-- *************** download  Ends here ************* -->

 </td>
 </tr> 
</tbody>
</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P>  Write a program to perform vector vector multiplication using CUBLAS1 library function call. <br>

</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify">
<span class = "content">

The input vectors are generated on <B> Host-CPU </b> and transfer the vectors to <B> Device-GPU </b> for 
vector multiplication  using <B> CUBALS1 </B> library call. The final output value is transferred 
back to <B> Host-CPU</b>.
</span>
</P>
</LI>

<LI><B>Input</B>
</LI>


<p> length of input vectors & generation of elements
</p> 



 <LI><B>Output</B>
</LI>

	
<p>  Scalar value 
</font>
</p>
<br>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ************************* example 2.2 ends **************************** -->

<!-- ******************* example 2.3 starts *********************************** -->

<a name="cuda-prog-number-id23"> </a>



<table border="0"  height="6">
<tbody>

 <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.3:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">

 <span class = "content">
     Write a Program for multiplication of a scalar with a  vector  and add the resultant vector 
        to  a vector using CUBLAS1 library  function calls. 
</span> 
<BR>

 
 <!-- *************** download  Starts here ****************** -->

(Download source code : 
<I>
 
  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CUBlasSVectScalarMult.cu">
 <font color = "blue"> CUBlasSVectScalarMult.cu </font>
  </a>)
  </I>
</span> </p>


<!-- ********************* download  Ends here ***************** -->

 </td>
 </tr> 
</tbody>
</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P>  Write a Program for multiplication of a scalar with a  vector  and add the resultant vector 
        to  a vector using CUBLAS1 library  function calls <br>

</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify">

Two  input vectors (<I> first, second </i>) and a scalar value is generated on <B> Host-CPU </b> and   multiplication of scalar value with  vector is done on <B> Device-GPU.</b>
Addition of   resultant vector  and second vector is computed  on <b> Device-GPU </b>  to obtain 
the solution vector, which is transferred back to <b> Host-CPU</b>. </P>
</LI>

<LI><B>Input</B>
</LI>


<p> length of input vectors and elements of the vector. </p> 



 <LI><B>Output</B>
</LI>

	
<p>  Solution Vector
</p>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ************************** example 2.3 ends ********************************** -->

<!-- *********************** example 2.4 starts *********************************** -->

<a name="cuda-prog-number-id24"> </a>



<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.4:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
    Write a Program for Matrix Vector multiplication using CUBLAS2 library function calls. 


 
 <!-- **************** download  Starts here *************** -->
<BR> 
(Download source code : 
<I>
  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CUBlasSVectMatMult.cu">
 <font color = "blue"> 
 CUBlasSVectMatMult.cu
</font></a> </I>)

&nbsp;  &nbsp;


<!-- ******************* download  Ends here ******************** -->

 </td>
 </tr> 
 
</tbody>

</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P>  Write a program to perform matrix vector multiplication using CUBLAS2 library function call.<br>

</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify"> 

<span class = "content">

The input matrix and input vector is generated on the <B> Host-CPU.</b> In simple algorithm, the input matrix is 
partitoned as per Grid of thread blocks. Each thread reads one row of the matrix  and performs
computation with column of the vector to obtain resultant vector on <b> Device-GPU</b>. The resultant
 
solution vector is transferred back to <b> Host-CPU</b>.  The <B> CUBLAS2 library call performs 
comptuation on the <B> Device-GPU</b>.
</span>
</P>

</LI>

<LI><B>Input</B>
</LI>


<p> Matrix Size 
 </p> 



 <LI><B>Output</B>
</LI>

	
<p>  execution time in seconds,Gflops achieved
</font>
</p>
<br>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ********************** example 2.4 ends ***************************** -->

<!-- ******************** example 2.5 starts ***************************** -->

<a name="cuda-prog-number-id25"> </a>



<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.5:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
     Write a Program for Matrix Matrix multiplication using CUBLAS3 library function 
     calls. 


 
 <!-- **************** download  Starts here *************** -->
<BR> 
(Download source code : 
<I>
 
<a href="../gpu-comp-nvidia-cuda-num-library-codes/CUBlasSMatMatMult.cu">
 <font color ="blue"> CUBlasSMatMatMult.cu </font> 
</a> </I>)
&nbsp;  &nbsp;

<!-- *************** download  Ends here *************** -->

 </td>
 </tr> 
 </tbody>
</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P> Write a Program to perform matrix matrix multiplication using CUBLAS3 library function calls.<br>

</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify">


Two input matrices  are generated on the <B> Host-CPU.</b> In simple algorithm, the input matrix is 
partitoned as per Grid of thread blocks. Each thread reads one row of the matrix  and performs
computation with one column of the another matrix and compute the correspodning  elements of resultant marix on <b> Device-GPU</b>. The resultant
matrix  is transferred back to <b> Host-CPU</b>.  The <B> CUBLAS3 </b> library call performs 
computation on the <B> Device-GPU</b>. 
</P>
</LI>

<LI><B>Input</B>
</LI>


<p> 
Matrix Size
 </p> 



 <LI><B>Output</B>
</LI>

	
<p> execution time in seconds,Gflops achieved
</font>
</p>
<br>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ********************************* example 2.5 ends ********************************* -->


<!-- ************************ example 2.6 starts ***************  -->

<a name="cuda-prog-number-id26"> </a>



<table border="0"  height="6">
<tbody>

   <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.6:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
     Write a CUBLAS CUDA Program for  implement solution of matrix system of linear 
equations Ax=b by Jacobi method 


 
 <!-- **************** download  Starts here *************** -->
<BR> 
(Download source code : 
<I>

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CUBlasJacobi.cu">
  <font color ="blue"> CUBlasJacobi.cu

  </font></a> </I>)
&nbsp;  &nbsp;



<!--***************** download  Ends here **************** -->

 </td>
 </tr> 
 </tbody>

</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P>  Write a CUBLAS CUDA program, for solving system of linear equations [A]{x} = {b} on  CUDA 
enabled NVIDIA  programming environment using Jacobi method<br>

</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify">

<p> The Jacobi iterative method is one of the simplest iterative techniques to solve system of 
linear equations.
    The <I>i<SUP>th</SUP></I> equation of a system of linear equations [A]{x}={b} is  <BR> </p>
 

<p align ="center"> <IMG SRC="../gpu-comp-nvidia-cuda-images/jacobi-sum13.gif" HEIGHT = 70 WIDTH = 350> </p> <BR>

 <p> If all the diagonal elements of <B>A</B> are nonzero (or are made nonzero
     by permuting the rows and columns of <B>A</B>), we can rewrite equation (1) </p> <BR>

 <p align ="center"> <IMG SRC="../gpu-comp-nvidia-cuda-images/jacobi-sum14.gif" HEIGHT=84 WIDTH=350> </p> <BR>

<P>
  The Jacobi method starts with an initial guess <I>x</I><SUB>0</SUB> for
  the solution vector <I>x</I>. This initial vector <I>x</I><SUB>0</SUB>
  is used in the right-hand side of equation (2) to arrive at the next approximation
  <I>x</I><SUB>1</SUB> to the solution vector. The vector <I>x</I><SUB>1</SUB>
  is then used in the right hand side of equation (2), and the process continues
  until a close enough approximation to the actual solution is found. A typical
  iteration step in the Jacobi method is </p>

<p align="Center"> <IMG SRC="../gpu-comp-nvidia-cuda-images/jacobi-sum15.gif" HEIGHT=86 WIDTH=350> </p> <br>

 
  We now express the iteration step of equation 3 in terms of residual <I>r<SUB>k</SUB></I>. 
  Equation (3) can be rewritten as  <br>

<p align = "Center" > <IMG SRC="../gpu-comp-nvidia-cuda-images/jacobi-sum16.gif" HEIGHT=86 WIDTH=350> </p>  <br> 

</P>
</LI>

<LI><B> Implementation </B>
  The input matrix and the right hand-side vector, intial soultion vector is generated on <B> Host-CPU </b> and transferred to <b> Device-GPU</b>. In simple algorithm, the input matrix is 
partitoned as per Grid of thread blocks. Each thread reads one row of the matrix A and performs
computation with vector and  update the solution vector. Convergence of the solution is checked 
and the 
solution vector is transferred back to <b> Host-CPU</b>.   <Br> <BR>



<LI><B>Input</B>
</LI>


<p> Size of Input Matrix and  the Vector 
 </p> 



 <LI><B>Output</B>
</LI>

	
<p>  The solution  of matrix system of linear equations <B>Ax = b </B>
</font>
</p>
<br>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ********************* example 2.6 ends ***************************** -->

<!-- ************************ example 2.7 starts ***************  -->

<a name="cuda-prog-number-id27"> </a>



<table border="0"  height="6">
<tbody>

   <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.7:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
    Write a CUDA program to implement the  solution of Matrix system of Linear Equations  AX=b  by Conjugate 
        Gradient method (Iterative Method).  

<!-- **************** download  Starts here *************** -->
<BR> 
(Download source code : 
<I>

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/CUBlasConjugateGradient.cu">
  <font color ="blue"> CudaConjugateGradient.cu) </font>
  </a>
  </I>
&nbsp;  &nbsp;


<!--***************** download  Ends here **************** -->


 </td>
 </tr> 
 </tbody>

</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<P align = "justify"> 
<span class = "content">
CUDA implementaiton for Conjugate Gradient Method to solve the system of 
linear equations [A]{x}={b}. Assume that A is symmetric positive definite matrix.    
</span> </p>


</LI>
</A>

<LI><B> Description </B>										
<P align = "justify"> 
<span class = "content">
<B>Description of  conjugate gradient method :</B> <BR> <BR>


 The conjugate gradient (<I>CG</I>) method is an example of minimizing
 method. A real n x n matrix A is positive definite if <I>x<SUP>T </SUP></I><B>A</B><I> x &gt; </I>{0} 
 for any <I>n</I> x 1 real, nonzero vector <I>x. </I>For a symmetric positive definite matrix <B>A</B>, 
 the unique vector <I>x</I> that minimizes the quadratic functional <BR> <BR>

  <FONT COLOR="#ff00ff"> 
 f(<I>x</I>) = (1<I>/</I>2)<I>x<SUP>T</SUP></I><B>A</B><I>x-x<SUP>T</SUP>b</I>&nbsp;  </FONT> <BR> <BR>


   is the solution to the system <B>A<I>x</I></B><I> </I>= <B>b</B>, here <I>x </I>and b 
   are <I>n </I>x 1 vectors. It is not particularly relevant
   when <I> n </i>  is very large, since the conjugating time for that number of iterations
   is usually prohibitive and the property does not hold in presence of rounding
   errors. The reason is that the gradient of functional f (<I>x</I>)<I> </I>is
   <B>A<I>x</I></B><I> - <B>b</B></I>, which is zero when f (<I>x</I>) is
    minimum. The gradient of a function is a <I>n</I> x 1 vector. We explain
   some important steps in the algorithm. An iteration of a minimization method
   is of the form <BR> <BR>

        <DIR>  <FONT COLOR="#ff00ff"> 
         <I>x<SUB>k+</SUB></I><SUB>1</SUB><I> </I>= <I>x<SUB>k</SUB>&nbsp;
             +<SUB> </SUB></I>tau<I><SUB>k</SUB></I>d<I><SUB>k</SUB></I> &nbsp; &nbsp;  </FONT>         
           (1)&nbsp;
           <BR>&nbsp;
        </DIR>
<BR>

     where  tau<I><SUB>k</SUB></I> is a scalar step size and d<I><SUB>k</SUB></I>is
     the direction vector, d<I><SUB>k </SUB></I>is a descent direction for f
     at <I>x</I>.&nbsp; We now consider the problem of determining tau<I><SUB>k</SUB></I>,
     given <I>x<SUB>k</SUB></I> and d<I><SUB>k</SUB></I>, so that f(<I>x</I>)
     is minimized on the line <I>x<SUB> </SUB></I>= <I>x<SUB>k</SUB></I> + tau<I><SUB>k</SUB></I>
     d<I><SUB>k</SUB></I>, for tau<I><SUB>k</SUB></I>. The function f(<I>x<SUB>k</SUB></I>+
     tau<I> </I>d<I><SUB>k</SUB></I>) is quadratic in tau, and its minimization
     leads to the condition <BR> <BR>

  <DIR>  <FONT COLOR="#ff00ff"> 
         tau<I><SUB> k </SUB></I>=&nbsp; g<I><SUB>k</SUB><SUP>T</SUP></I>g<I><SUB>k
     </SUB>/</I> d<I><SUB>k</SUB><SUP>T</SUP></I><B>A</B>d<I><SUB>k</SUB> </i>,  </FONT>                                
         &nbsp;&nbsp; (2)&nbsp;
 </DIR>
 <BR>

    where g<I><SUB>k</SUB>=</I><B>A</B><I>x<SUB>k </SUB>- </I><B>b</B><I> </I>is
    the gradient (residue)&nbsp; vector after <I>k</I> iterations. The residual
    need not be computed explicitly in each iteration because it can be computed
    incrementally by using its value from the previous iteration. In the (<I>k+</I>1)<I><SUP>th
   </SUP></I>iteration, the residual g<SUB><I>k+</I>1</SUB> can be expressed
    as follows:&nbsp; <BR> <BR>

    &nbsp;&nbsp;&nbsp;&nbsp;
    <FONT COLOR="#ff00ff"> 
    g<SUB><I>k+</I>1</SUB><I>&nbsp; </I>=<I> </I><B>A</B><I>x<SUB>k+</SUB></I><SUB>1</SUB><I>
    -</I> <I>b&nbsp;</I>&nbsp; </FONT>

    <DIR>  <FONT COLOR="#ff00ff"> 
          &nbsp;&nbsp;&nbsp;&nbsp; =<I> </I><B>A</B>(<I>x<SUB>k</SUB></I>+ tau<I><SUB>k
         </SUB></I>d<I><SUB>k</SUB></I>) <I>- b</I>&nbsp; 
   <BR>
   
          &nbsp;&nbsp;&nbsp;&nbsp; = <B>A</B><I>x<SUB>k</SUB>- b + </I>tau<I><SUB>k
         </SUB></I><B>A</B>d<I><SUB>k&nbsp;</SUB></I>&nbsp;
   <BR> <BR>

   &nbsp;&nbsp;&nbsp;&nbsp; 
       = g<I><SUB>k </SUB>+ </I>tau<I><SUB>k </SUB></I><B>A</B>d<I><SUB>k </sub> 
                                </i> &nbsp; &nbsp; 
 </FONT>  (3) 
   </DIR> <BR> <BR>

</span> </p>
<P align = "justify"> 
<span class = "content">

   Thus, the only matrix-vector product computed in each iteration is <B>A</B>d<I><SUB>k</SUB></I>,
   which is already required to compute tau<I><SUB>k&nbsp; </SUB></I>in the
   equation (2). If <B>A </B>is a symmetric positive definite matrix and d<SUB>1</SUB><I>,
   </I>d<SUB>2<I>,</I>..., </SUB>d<I><SUB>n</SUB></I> are direction vectors
   that are conjugate with respect to <B>A </B>(that is, d<I><SUB>i</SUB><SUP>T
   </SUP></I><B>A</B>d<I><SUB>j</SUB>=</I>0 for all 0<I>&lt;n, j&lt;=n</I>,<I> i</I>!=<I>j</I>), 
   then <I>x<SUB>k+</SUB></I><SUB>1</SUB> in the Equation (1) converges to the solution 
   of <B>A</B><I>x = </I>bin at most <I>n</I>
   iterations, assuming no rounding errors. <br> <BR>


   In practice, however, the number of iterations that yields an acceptable approximation to the solution is
   much smaller than <I>n</I>.&nbsp; It&nbsp; also&nbsp; makes the gradient
   at <I>x<SUB>k+</SUB>1</I> orthogonal to search direction, i.e&nbsp; d<SUB>k</SUB><I><SUP>T
   </SUP></I>g<SUB><I>k+</I>1</SUB><I>&nbsp; = </I>0.&nbsp; Now we suppose that the search directions
   are determined by an iteration of the form&nbsp; <BR> <BR>

  <DIR>  <FONT COLOR="#ff00ff"> 
    d<SUB><I>k+</I>1</SUB><I> </I>=<I> -</I>g<SUB><I>k+</I>1</SUB>+ beta<I><SUB>k
    </SUB></I>d<I><SUB>k&nbsp;</SUB> </i> &nbsp; &nbsp; </FONT> (4) 
  </DIR> <BR> <BR>

</span> </p>
<P align = "justify"> 
<span class = "content">

    where d<SUB>0<I> </I></SUB>=<I> -</I>g<SUB>0</SUB><I>&nbsp;</I> and beta<SUB>0</SUB>,
    beta<SUB>1</SUB> , ...... remain to be determined. We find the new search
    direction in the&nbsp; plane spanned by the gradient at the most recent
    point and previous search direction. The parameter beta<SUB><I>k+</I>1</SUB>i<I>s </I> determined by following       
   equation <BR> <BR>

  <DIR>  <FONT COLOR="#ff00ff"> 
    Beta<SUB><I>k+</I>1</SUB><I> </I>= g<I><SUP>T</SUP><SUB>k+</SUB></I><SUB>1</SUB>Ad<I><SUB>k</SUB></I>/
    d<I><SUP>T</SUP><SUB>k</SUB></I>Ad<I><SUB>k</SUB></i> &nbsp; &nbsp; </FONT> (5) 
  </DIR> 
  <BR>


  And, one can derive orthogonality relations<BR>&nbsp;

   <DIR>  <FONT COLOR="#ff00ff"> 
      g<I><SUP>T</SUP><SUB>k</SUB></I>g <I><SUB>l</SUB></I>= 0 (<I>l </I>!=
      <I>k</I>); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

      d<I><SUP>T</SUP><SUB>k</SUB></I>Ad<I><SUB>l </SUB></I>= 0 (<I>l </I>!=<I>k</I>) </FONT>
   </DIR>
 <BR>

 <BR>
      The derivation of the above equation (5)&nbsp; and orthogonality relations
      is beyond the scope of this document. For details please refer [ ]. Using
      equation (3) and orthogonality relations, the equation (5)&nbsp; can be
      further reduced to <BR> <BR>
  <DIR>
 <FONT COLOR="#ff00ff"> 
   Beta<I><SUB>k+</SUB>1 </I>= g<I><SUP>T</SUP><SUB>k+</SUB>1</I>g<I><SUB>k+</SUB>1</I>/
    g<I><SUP>T</SUP><SUB>k</SUB></I>g<I><SUB>k</SUB><</i> &nbsp; &nbsp; </FONT>  (6) 
 </DIR> <BR> <BR>

</span> </p>
<P align = "justify"> 
<span class = "content">

   The above equations (1) to (6) lead to <I>CG</I> algorithm. The algorithm
   terminates when the square of the Euclidean vector norm of gradient (residual)
   falls below a predetermined tolerance value.&nbsp; Although all of the
   versions of the conjugate gradient method obtained by combining the formulas
   for g<I><SUB>k</SUB></I>, Beta<I><SUB>k</SUB></I>, and tau<I><SUB>k</SUB></I>
   in various ways are mathematically equivalent, their computer implementation
   is not. The following version is compared with respect to computational
   labor, storage requirements, and accuracy. The following sequence of steps
   are widely accepted.
  <BR>



 <DIR>  <FONT COLOR="#ff00ff"> 
      1. tau<I><SUB> k&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </SUB></I>=&nbsp;
         g<I><SUB>k</SUB><SUP>T</SUP></I>g<I><SUB>k </SUB>/</I>        
        d<I><SUB>k</SUB><SUP>T</SUP></I><B>A</B>d<I><SUB>k</SUB></I>&nbsp; <BR>


      2. <i> x<SUB>k+</SUB>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </I>= 
         <I>x<SUB>k</SUB>&nbsp; +<SUB> </SUB></I>tau<I><SUB>k</SUB> </I>d<I><SUB>k</SUB></I>&nbsp; <BR>

      3. g<I><SUB>k+</SUB>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </I>=<I>&nbsp;</I> 
          g<I><SUB>k </SUB>+ </I>tau<I><SUB>k </SUB></I><B>A</B>d<I><SUB>k&nbsp;</SUB></I>&nbsp; <BR>

      4. Beta<I><SUB>k+</SUB>1 </I>= g<I><SUP>T</SUP><SUB>k+</SUB>1</I>g<I><SUB>k+</SUB>1</I>/
         g<I><SUP>T</SUP><SUB>k</SUB></I>g<I><SUB>k</SUB></I>&nbsp; <BR>

      5. d<I><SUB>k+</SUB>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </I>=<I> -</I>g<I><SUB>k+</SUB>1 </I>+          
         Beta<I><SUB>k </SUB></I>d<I><SUB>k</SUB></I>&nbsp; <BR>
</FONT>

  </DIR> <BR>

   where <I>k</I> = 0, 1, 2, .......... Initially we choose <I>x</I><SUB>0</SUB>, 
        calculate g<SUB>0</SUB> = A<I>x</I><SUB>0 </SUB>- b , and put d<SUB>0</SUB>= -g<SUB>0</SUB>&nbsp;


<!-- ****** Example 2.7: Conjugate Gradient  Method   implementation  Algorithm  ********* -->

<BR> <BR>

  The computer implementation of this algorithm is explained as follows : <BR> <BR>

   <FONT COLOR="#ff00ff"> 

    void CongugateGradient(float

   <I> x<SUB>0</SUB> </I>[ ],  <i> float b [ ], float d)&nbsp;  </i> <BR>

 <i>  &nbsp; &nbsp; {&nbsp;  </i> <BR>

 <i>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      float &nbsp;&nbsp; g, Delta0, Delta1, beta;&nbsp; </i> <BR>

   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 <i>  float &nbsp;&nbsp; temp, tau;&nbsp;  </i> <BR>
   
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 <i>  int &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; iteration;  </i> <BR>


<I> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; iteration = 0; </i><BR>

<I> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x &nbsp; =  <I>x<SUB>0</SUB></I><SUB>;&nbsp;</SUB>&nbsp;
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  g = b;&nbsp;  </i><BR>

<i>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g = A <I>x - </I>g;&nbsp;<BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Delta0 = g<SUP>T </SUP>* g;&nbsp; &nbsp; </i> <BR>

<I> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if ( Delta0 &lt;= EPSILON)&nbsp; </i> <BR>

<I> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    return; &nbsp; </i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d = -g;&nbsp; </i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; do {&nbsp; </i> <BR>

<I> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   iteration = iteration + 1;&nbsp; </i> <BR>


<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   temp = A * d;&nbsp;&nbsp; </i> <BR>


<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   tau = Delta0 / d<I><SUP>T&nbsp;</SUP></I> * temp;&nbsp;&nbsp; <BR>

<I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  x</I> = <I>x</I> + tau * d;&nbsp;&nbsp;  </i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   g = g + tau * temp;&nbsp;&nbsp; </i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   Delta1 = g<I><SUP>T&nbsp;</SUP></I> * g; </i> <BR>


<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  if ( Delta1 &lt;= EPSILON )&nbsp;&nbsp; </i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;&nbsp;</i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   beta = Delta1 / Delta0;&nbsp;&nbsp; </i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
     Delta0 = Delta1;&nbsp;&nbsp; </i> <BR>

<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   d = -g + beta * d;&nbsp;&nbsp; </i> <BR>


<i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} 
 while(Delta0 &gt; EPSILON &amp;&amp; Iteration &lt; MAX_ITERATIONS); </i><BR>

<i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return; </i><BR>

 </i> </FONT>&nbsp;

</span> </p>
<P align = "justify"> 
<span class = "content">

   Regarding one-dimensional arrays of size <I>n </I>x 1 are required for
   temp, g, <I>x, </I>d. The storage requirement for matrix. A is depends upon the structure 
   ( dense, band, sparse )  of the matrix.The two dimensional <I>n</I> x <I>n</I> array is the 
   simplest structure to store  matrix A. For large sparse matrix A this structure wastes a large amount 
    of storage space, for such matrix A suitable storage scheme should be 
    used.
<BR> <BR>


<!-- ****************** Example 2.7 : Conjugate Gradient  Method  Ax=B matrix system : [Objective & Description ] Ends ********** -->


<!-- ************* Example 2.7 : Conjugate Gradient  Method  Ax=B matrix system : [Objective & Description ] 
                         Pre-condicitoned CG method Starts ************ -->
</span> </p>
</li>

<LI>
  <B>The preconditioned conjugate gradient algorithm&nbsp;</B>&nbsp;  </LI> <Br> <BR>

<P align = "justify"> 
<span class = "content">
 
    Let C be a positive definite matrix factored in the form C = E E<I><SUP>T</SUP></I>, 
    and let the quadratic functional&nbsp;  </FONT>
 
 <BR> 

  <DIR>  <FONT COLOR="#ff00ff"> 
    f(<I>x</I>) = (1<I>/</I>2)<I>x<SUP>T</SUP></I><B>A</B><I>x - x<SUP>T</SUP>b + C </I>,&nbsp;
</FONT>
  </DIR>
 <BR>

  We define second quadratic functional g(y) by the transformation y = E<I><SUP>T</SUP>x</I>,<BR> <BR>


  <DIR>  <FONT COLOR="#ff00ff"> 
     g(<I>x</I>) = g(E<SUP>-T</SUP>y) = (1<I>/</I>2)<I>y<SUP>T</SUP></I><B>A<SUP>*</SUP></B><I>y
    - y<SUP>T</SUP>b <SUP>*</SUP> + C<SUP>*</SUP>

     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </I>where A <SUP>*</SUP> = E<SUP>-1</SUP>AE<SUP>-<I>T</I></SUP>, b<SUP>*</SUP> = 
         E<SUP>-1</SUP>b, C<SUP>*</SUP> = C.&nbsp; </FONT>
</DIR>
<BR>
  Here, A<SUP>*</SUP> is symmetric and positive definite. The similarity transformation <BR> <BR>

  <DIR>  <FONT COLOR="#ff00ff"> 

    E<SUP>-<I>T</I></SUP>A<SUP>*</SUP>E<I><SUP>T</SUP> </I>= E<SUP>-<I>T</I></SUP>E<SUP>-1</SUP>A
    = C<SUP>-1</SUP>A&nbsp; </FONT>

  </DIR>


</span> </p>
<P align = "justify"> 
<span class = "content">

   reveals that A<SUP>*</SUP> and A have same eigen values. If C can be found
   such that the condition number of the matrix A<SUP>*</SUP> is less than
   the condition number of the matrix A, then the rate of convergence of the
   preconditioned method is better than that of conjugate gradient method.
   We call C the <I>preconditioning </I>matrix, A<SUP>*</SUP> the <I>preconditioned</I>
   matrix, We assume that the matrix C = EE<SUP>T</SUP> is positive definite,
   since E is nonsingular by assumption. If the coefficient matrix A has <I>l</I>
   distinct eigen values, the CG algorithm  converges to the solution
   of the system <B>A<I>x</I> </B>=<B> b </B>in at most <I>l</I> iterations
   (assuming no rounding errors). Therefore, if A has many distinct eigen
   values that vary widely in magnitude, the CG algorithm may require a large
   number of iterations to converge to an acceptable approximation to the
   solution. <BR> <BR>



  The speed of convergence of the <I>CG</I> algorithm can be increased
  by preconditioning <B>A</B> with the congruence transformation <B>A*</B><I>
    = </I>E<SUP>-1</SUP>AE<SUP>-<I>T</I> </SUP> where E is a nonsingular
  matrix. E is chosen such that <B>A*</B> has fewer distinct eigen values
  than <B>A</B>. The <I>CG</I> algorithm is then used to solve <B>A* y <I>=</I>b<I>*</I></B>,
  where <I>x =</I>(E<I><SUP>T</SUP></I>)<I><SUP>-</SUP>1y</I> . The resulting
  algorithm is called the <I>preconditioned conjugate gradient</I> (<I>PCG</I>)
  algorithm. The step performed in each iteration of the preconditioned
 conjugate gradient algorithm are as follows <BR> <BR>

<DIR>  <FONT COLOR="#ff00ff"> 
 
 1. &nbsp; tau<I><SUB> k&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </SUB></I>=&nbsp;
     g<I><SUB>k</SUB><SUP>T</SUP></I>h<I><SUB>k </SUB>/</I>        
     d<I><SUB>k</SUB><SUP>T</SUP></I><B>A</B>d<I><SUB>k</SUB></I>&nbsp; <BR>

 2. &nbsp; <i> x<SUB>k+</SUB></I><SUB>1</SUB><I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </I>= <I>x<SUB>k</SUB> +<SUB> </SUB></I>tau<I><SUB>k</SUB> </I>d<I><SUB>k</SUB></I>&nbsp; <BR>

 3.&nbsp;  g<SUB><I>k+</I>1</SUB><I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </I>=<I>&nbsp;</I>
    g<I><SUB>k </SUB>+ </I>tau<I><SUB>k </SUB></I><B>A</B>d<I><SUB>k&nbsp;</SUB></I>&nbsp; <BR>

 4. &nbsp; h<SUB><I>k+</I>1</SUB><I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </I>=&nbsp;
    C<SUP>-1</SUP>g<SUB><I>k+</I>1</SUB>&nbsp; <BR>

 5. &nsbp;  beta<SUB><I>k+</I>1</SUB><I> </I>= g<I><SUP>T</SUP><SUB>k+</SUB></I><SUB>1</SUB>h<SUB><I>k+</I>1</SUB>/
    g<I><SUP>T</SUP><SUB>k</SUB></I>h<I><SUB>k</SUB></I>&nbsp; <BR>

 6. &nbsp;  d<SUB><I>k+</I>1</SUB><I>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </I>=<I>
    -</I>h<SUB><I>k+</I>1</SUB><I> </I>+ beta<SUB><I>k+</I>1</SUB>d<I><SUB>k</SUB></I>
</FONT>
</DIR>



<Br> <BR>
  where <I>k</I> = 0, 1, 2, .......... Initially we choose <I>x</I><SUB>0</SUB>, 
  calculate g<SUB>0</SUB> = A<I>x</I><SUB>0 </SUB>- b, h<SUB>0</SUB>= 
  C<SUP>-1</SUP>g<SUB>0</SUB> and d<SUB>0</SUB> = -h<SUB>0</SUB>. 

  The multiplication by C<SUP>-1</SUP> in step (4) is to be interpreted as solving a system of equations  
  with coefficient matrix C. A source of preconditioning matrices is the class
  of stationary iterative methods for solving the system 
 
  <B>A<I>x</I><SUP>*</SUP></B> = <B>b</B>.&nbsp;</DIR> 
</span> </p>

<!-- *************** Example 2.7 : Conjugate Gradient  Method  Parallel implementation of PCG Starts ************* -->
</li>

<LI> <B>Parallel implementations of the PCG algorithm</B> </li>


<P align = "justify"> 
<span class = "content">

The parallel conjugate gradient algorithm involves the following&nbsp;
   type of computations and communications <Br> <BR>

Partitioning of a matrix : The matrix A is obtained by discretization
of partial differential equations by finite element, or finite difference
method. In such cases, the matrix is either sparse or banded. Consequently,
the partition&nbsp; of the matrix onto <I>p</I> processes play a vital
role for performance. For, simplicity , we assume that <B>A </B>is symmetric
positive definite and  is<I> rowwise</I> block-striped partitioned.&nbsp;
<BR> <Br>

<BR><B>Scalar Multiplication of a vector and addition of vectors : </B> 
<BR>Each of these computations  can be performed sequentially regardless
of the preconditioner and the type of coefficient matrix. If all vectors
are distributed identically among the processes, these steps require no
communication in a parallel implementation. <Br> <BR>

<B>Vector inner products :</B> 

<BR>In some situations, partial vectors are available on each&nbsp; processes.&nbsp;
MPI Collective library calls are necessary to perform vector inner products&nbsp;
If the parallel computer supports fast reduction operations, such as optimized
MPI, then the communication time for the inner-product calculations can
be made minimum. <Br> <BR>

<B>Matrix-vector multiplication :</B>

<BR>The computation and the communication cost of the matrix-vector
multiplication;  depends on the structure of the matrix A. The
parallel implementation of the PCG algorithm for three cases one
in which A is a block-tridiagonal matrix of the  type, two in
which it is banded unstructured sparse matrix, and three in which the matrix
is sparse give different performance on parallel computers. Various
parts of the algorithm in each of the three cases dominate in terms of
communication overheads.<BR> <BR>

<B>Solving the preconditioned system :</B>
<BR>The PCG algorithm solves  system of linear equations in each
iteration The preconditioner C is chosen so that solving the system modified
system is in expensive compared to solving the original system of
equations <B>A<I>x </I></B>=  <B>b</B>. Nevertheless, preconditioning increases
the  amount of computation in each iteration. For good preconditioners,
however, the increase is compensated by a reduction in the number of iterations
required to achieve acceptable convergence. The computation and the
communication requirements of this step depends on the type
of preconditioner used. preconditioning method such as diagonal preconditioning,
in which the preconditioning matrix C has nonzero elements only
along the principle diagonal does not involve any communication Also,
Incomplete Cholesky (IC) preconditioning, in which C is based on incomplete
Cholesky factorization of A and it may involve different computations and
communications in parallel implementation. <br> <BR>

The convergence of CG method iterations performed by checking the error
criteria i.e. eulicidean norm of the residual vector should be less than
prescribed tolerance. This convergence check involves gathering of real
value from all processes, which may be very costly operation. <Br> <BR>

We consider parallel implementations of the PCG algorithm using
diagonal preconditioner for dense coefficient matrix type. As we
will see, if C is a diagonal preconditioner, then solving the modified
system does not require any interprocessor communication. Hence,
the communication time in a CG iteration with diagonal preconditioning
is the same as that in an iteration of the unpreconditioned algorithm. <Br> <BR> 

Thus the operations that involve any 
   communication overheads are computation of inner products, matrix-vector 
   multiplication and, in case of IC preconditioner solving the 
   system.
</span></p>

</LI>

<!-- ************** Example  2.7: Conjugate Gradient  Method  Parallel implementation of PCG Ends ************* -->




<LI><B>Input</B>


<P align = "justify"> 
<span class = "content">
 Input Matrix and Right Hand side Vector
</span> </p>
</li>


 <LI><B>Output</B>


<P align = "justify"> 
<span class = "content">	
  Solution x of linear system of matrix equations Ax = b

</span> </p>
</li>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</TD>
</tr>
</tbody>
</table>

<!-- ********************* example 2.7 ends ***************************** -->



<!-- ************************ example 2.8 starts ***************  -->

<a name="cuda-prog-number-id28"> </a>



<table border="0"  height="6">
<tbody>

   <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.8:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
     Write a CUBLAS CUDA program on sparse matrix multiplication of size n x n and vector 
     of size n. <font color ="red">  (Assignment) </font> 

 
 <!-- **************** download  Starts here *************** -->
<!-- **** 
<BR> 
(Download source code : 
<I>

  <a href="../gpu-comp-nvidia-cuda-num-library-codes/SPmv_GPU.cu">SPmv_GPU.cu
  </a> || <a href="../gpu-comp-nvidia-cuda-num-library-codes/SPmv_cudpp.cu">
  <font color ="blue"> SPmv_cudpp.cu  </font>
  </a>)
   </I>
&nbsp;  &nbsp;

<BR> 
(Download Make File : 
<I>
 <font color ="#CC66CC">
  <a href="../gpu-comp-nvidia-cuda-num-lib-codes/Makefile-sparse">Makefile-sparse
  </a>)
  </font></I>
&nbsp;  &nbsp

*** -->

<!--***************** download  Ends here **************** -->

 </td>
 </tr> 
 </tbody>

</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P> To write a CUBLAS CUDA program on sparse matrix multiplication of size n x n and vector of size n.<br>

</P>
</LI>
</A>

<LI><B>  Efficient storage format for sparse matrix </B>										
<P align="justify">
Dense matrices are stored in the computer memory by using two-dimensional arrays. For example,
 a matrix with n rows and m columns, is stored using a n x m array of real numbers. However, using the same two-dimensional 
array to store sparse matrices has two very important drawbacks. First, since most of the entries in the sparse matrix 
are zero, this storage scheme wastes a lot of memory. Second, computations involving sparse matrices often need to operate only 
on the non-zero entries of the matrix. Use of dense storage format makes it harder to locate these non-zero entries. For these 
reasons sparse matrices are stored using different data structures. <BR> <BR>

The Compressed Row Storage format (CRS) is a widely used scheme for storing sparse matrices. In the CRS format, a 
sparse matrix A with n rows having k non-zero entries is stored using three arrays: two integer arrays rowptr and colind, 
and one array of real entries values. The array rowptr is of size n+1, and the other two arrays are each of size k. The 
array colind stores the column indices of the non-zero entries in A, and the array values stores the corresponding non-zero 
entries. In particular, the array colind stores the column-indices of the first row followed by the column-indices of the 
second row followed by the column-indices of the third row, and so on. The array rowptr is used to determine where the storage of the 
different rows starts and ends in the array colind and values. In particular, the column-indices of row i are stored starting at colind [rowptr[i]]
 and ending at (but not including) colind [rowptr[i+1] ]. Similarly, the values of the non-zero entries of row i are stored at values [rowptr[i] ] 
and ending at (but not including) values [rowptr[i+1] ]. 
Also note that the number of non-zero entries of row i is simply rowptr[i+1]-rowptr[i]. </P>
</LI>

<LI> <b> Serial sparse matrix vector multiplication </b>
<P align="justify">
The following function performs a sparse matrix-vector multiplication [y]={A} {b} 
where the sparse matrix A is of size n x m, the vector b is of size m and the vector 
y is of size n. Note that the number of columns of A (i.e., m ) is not explicitly 
specified as part of the input unless it is required.  </P>

<FONT COLOR="#ff00ff"> 
 void SerialSparseMatVec(int <I>n</I>, int *<I>rowptr</I>, int *<I>colind</I>, double *<I>values</I> <BR>

    double *<I>b</I>, double&nbsp; *<I>y</I>)&nbsp; &nbsp; <BR>

    {&nbsp;<BR>
     &nbsp; &nbsp; &nbsp; int <I>i</I>, <I>j</I>, <I> count </i>; &nbsp;<BR>
 
    &nbsp; &nbsp; &nbsp; count = 0; <BR>
    &nbsp; &nbsp; &nbsp; for(<I>i</I>=0;  <I>i</I>&lt;<I>n</I>; <I>i</I>++) <BR>


    &nbsp; &nbsp; &nbsp; { <BR>

    &nbsp; &nbsp; &nbsp; &nbsp; <I>y</I>[<I>i</I>] = 0.0; <BR>
  


    &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; 
    for (<I>j</I>=<I>rowptr</I>[<I>i</I>]; <I>j</I>&lt;<I>rowptr</I>[<I>i+</I>1]; &nbsp; </I>j</I>++) <BR>


    &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <I>y</I>[<I>i</I>] += value [count] * b [<I>colind</I>[<I>j</I>]];  <BR>
    &nbsp; &nbsp; &nbsp; &nbsp; count ++;  <BR> 
     &nbsp; &nbsp; &nbsp;  } <Br> 
    } <BR> </font> <BR>
 </font>
   </P>

</LI>
<LI><b> Description of parallel algorithm</b>
<P align="justify">

In the parallel 

implementation, each thread picks a row from the 
matrix and multiplies it with the vector. Thus computation of all threads
 is carried out in parallel.
</P>
</LI>


<LI> <b>Implementation</b>
<P align="justify">

There are two implementations, one using CUDA kernels and the other using CUDPP library.<br><br>
<b>CUDA implementation</b><br><br>

<b>Step 1:</b> The matrix size(no. of  rows) and sparsity(percentage of non-zero) are provided by the user in the cmd line.<br><br>
<b>Step 2:</b> A sparse matrix and a vector of the given size are allocated and initialized. Also the row_ptr and 
col_idx vectors are created and assigned their appropriate based on the sparse matrix<br><br>
<b>Step 3:</b>  The above vectors are also created and initialized on the device (GPU).<br><br>
<b>Step 4:</b>  The sparse_matrix and vector are multiplied in the GPU to obtain the result.<br> <BR>


<b>CUDPP implementation</b><br><br>

<b>Steps 1 and 2 are same as above</b><br><br>
<b>Step 3:</b> Only two vectors are allocated on the Device-GPU, the vector to be multiplied and a vector to store the result.<br><br>
<b>Step 4:</b> A sparse matrix object is created using CUDPPHandle (object pointer) and a CUDPPConfiguration 
(a structure containing the specifications of the algorithm, in this case sparse_matrix vector multiplication).<br><br>
<b>Step 5:</b> The multiplication of sparse matrix and vector are performed calling the CUDPP library procedure  
cudppSparseMatrixVectorMultiply() which perfroms the mulitiplication in the GPU.


</P>
</LI>
<LI> <b> <font color = "red" > CUDA API used: </font> </b>
<P align="justify">

<b> cudaMalloc(void** array, int size<i>)</i></b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
<Br> // allocates memory on device <br><br>

<b> cudaFree(void* array )</b>	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	
<BR> 	// frees memory allocated on device<br><br>

<b> cudaMemcpy((void*)device_array, (void*)host_array, size , cudaMemcpyHostToDevice )</b>  &nbsp;&nbsp;&nbsp; <BR> // copies from host to device<br><br>

<b> cudaMemcpy((void*)host_array, (void*)device_array, size , cudaMemcpyDeviceToHost )</b>  <BR> // copies from device to host<br><br>

</P>
</LI>

<LI> <b><font color = "red" > CUDPP API used: </font> </b>
<P align="justify">

<b> cudppSparseMatrix(&sparseMatrixHandle, config, no_of_non_zero,  no_of_rows, (void *) matrix, (unsigned int *) row_ptr, (unsigned int *)col_idx);</b>	
<br>
&nbsp;&nbsp;&nbsp;  //this fucntion creates a sparse matrix object assigned to the  sparseMatrixHandle.<br><br>

<b> cudppSparseMatrixVectorMultiply(sparseMatrixHandle, result, vector); </b>	&nbsp;&nbsp;&nbsp;	<BR> // performs the multiplication

</P>
</LI>

<LI><B>Performance:</B>
<P align="justify">
The gettimeofday() function which is part of sys/time.h is used to measure the time taken for computation. <Br> <BR>
</LI>



<LI><B>Input</B>
</LI>


<P align="justify"> The input to the problem is given as arguments in the command line. It should be given in the following format ;
Suppose that the number of rows of the sparse matrix is n (only square matrices are considered) and 
the sparsity i.e. the percentage of number of zero's (given in the range 0 to 1) is m, then the  program must be run as,<br><br>
    <b> ./program_name n m </b><br><br>
CPU generates the sparse matrix, the vector to be multiplied using random values and the row_ptr and col_idx vectors based on the sparse matrix.

 </p> 



 <LI><B>Output</B>
</LI>

	
<p>  The CPU prints the time taken for the computation.
</font>
</p>
<br>

 <DIV ALIGN=right>
   <A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
   </DIV>


</UL>


</TD>
</tr>
</tbody>
</table>

<!-- ********************* example 2.8 ends ***************************** -->


<!-- ******************** example 2.9 starts ***************************** -->

<a name="cuda-prog-number-id29"> </a>



<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.9:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
       Write a CUDA program for matrix into matrix multiplication using vendour supplied BLAS libraries (DGEMM)
         on host-CPU &amp; Device-GPU to perform computations on host-CPU &amp; device-GPU and extract performance 
         in Gigaflops 

 <!-- **************** download  Starts here *************** -->
<BR> <BR>
( Download  WinRAR ZIP archive: <BR>
<I>
 
<a href="../gpu-comp-nvidia-cuda-num-library-codes/Cuda_GPU_DGEMM.zip">
 <font color ="blue"> Cuda_GPU_DGEMM (WinRAR ZIP archive)</font> 
</a> </I>)
 </td>
 </tr> 
 </tbody>
</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P> Write a CPU-GPU CUDA Program to extract performance of  matrix matrix multiplication by performing 
computations on host-CPU &amp; Device-GPU <br>

</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify">


Two input matrices  are generated on the <B> host-CPU</b> In simple algorithm, the input matrix is 
partitoned into two different blocks to perform comptuations on host-CPU &map; device-GPU as per Grid of 
thread blocks.   The <B> CUBLAS3 </b> library call performs 
computation on the <B> Device-GPU</b> and vendor supplied DGEMM libraries such as intel MKL perform computations
on host-CPU.
</P>
</LI>

<LI><B>Input</B>
</LI>


<p> 
Size (Row size, Column size)  of the Input matrices and their elements.
 </p> 



 <LI><B>Output</B>
</LI>

	
<p>  Performance in terms of GFlops.
</font>
</p>
<br>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ********************************* example 2.9 ends ********************************* -->



<!-- ******************** example 2.10 starts ***************************** -->

<a name="cuda-prog-number-id210"> </a>



<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.10:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
       Write a CUDA program for matrix into matrix multiplication using 
vendour supplied CUDA BLAS libraries (DGEMM) and extract the performance in 
terms of Gflops.


 
 <!-- **************** download  Starts here *************** -->
<BR> <BR>
( Download  WinRAR ZIP archive: <BR>
<I>
 
<a href="../gpu-comp-nvidia-cuda-num-library-codes/Cuda_CPU_GPU_DGEMM.zip">
 <font color ="blue"> Cuda_CPU_GPU_DGEMM (WinRAR ZIP archive)</font> 
</a> </I>)


<!-- *************** download  Ends here *************** -->

 </td>
 </tr> 
 </tbody>
</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<font size="2">
<P> Write a CUDA program for matrix into matrix multiplication using 
vendour supplied CUDA BLAS libraries (DGEMM) and extract the performance in 
terms of Gflops.
<br>

</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify">


Memory is allocated for two input matrics on host-cpu and device-gpu.
 Initialized input matrices on  host-cpu.Inputs matrics are copied from host-cpu 
to device-gpu.Then CUBLAS3  library function DGEMM is called to 
performs matrix-matrix  computation on the  Device-GPU. The resultant matrix
 is copied back from device-gpu to  host-cpu.</P>
</LI>

<LI><B>Input</B>
</LI>


<p> 
Size of the matrix row size, matrix column size  
</p> 



 <LI><B>Output</B>
</LI>

	
<p>  Time Taken for computation , Gflop/s
</font>
</p>
<br>

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ********************************* example 2.10 ends ********************************* -->




<!-- ******************** example 2.11 starts ***************************** -->

<a name="cuda-prog-number-id211"> </a>



<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.11:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
      	Write a CUDA program to Demonstrate the Performance of Matrix Matrix Multiplication and extract the performance in terms of Gflops.


 
 <!-- **************** download  Starts here *************** -->
<BR> <BR>
( Download  source code : 
<I>
 
<a href="../gpu-comp-nvidia-cuda-num-library-codes/gpgpu_mat-mat-Mul-Perf.cu">
 <font color ="blue">gpgpu_mat-mat-Mul-Perf.cu </font></a></I>;<br>
  <a href="../gpu-comp-nvidia-cuda-num-library-codes/Makefile_gpgpu-mat-mat-Mul-Perf">
 <font color ="blue">Makefile_gpgpu-mat-mat-Mul-Perf </font>
  
</a> </I>)


<!-- *************** download  Ends here *************** -->

 </td>
 </tr> 
 </tbody>
</table>


<table  height="6">
<tbody>
<tr> 
<TD>
<UL>
<LI><B> Objective </B>

<P> 

Performance of Matrix Matrix Multiplication 
</P>
</LI>
</A>

<LI><B> Description </B>										
<P align="justify">

Provided are 3 functions to show Matrix Matrix Multiplicaiton performance on GPU's. Each function exploits
			 			 various hardware features of GPU's to gain performance. One can notice performance will double each time as 
			 			 one goes from executing from function 1 to 3.   <br>
			 			 Features that are exploited:<br>
			         	 1)Block Size 2)Thread Mapping 3)Shared Memory 4)Global Memory Bandwidth 5)Registers 6)Scheduling 7)Tiling<br>
						 Lower &lt;function numbers&gt; may not exploit all these features (or to a lesser degree) but as the &lt;function number&gt; 				 						 increases features will be exploited more agressively. <br> 
 
			 			 Function Name: matMulBlockwise&lt;function number&gt; - function that performs matrix matrix multiplication
</P>
</LI>

<LI><B>Input</B>
</LI>


<p> 
Set &lt;Square Matrix Size&gt; &lt;Shared Memory Size&gt; &lt;GPGPU Device Number&gt; &lt;Function Number&gt;<br>
 			 			 1) &lt;Shared Memory Size&gt; can only take 16, 32, 48 as values <br>
			 			 2) &lt;Function Number&gt; can only take 1, 2, 3 as values

</p> 



 <LI><B>Output</B>
</LI>

	
<p> 
Time taken and gflops for Matrix Matrix Multiplication in individual function runs based on &lt;Function Number&gt;.
</p>
<br>

</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ********************************* example 2.11 ends ********************************* -->




<!-- ******************** example 2.12 starts ***************************** -->

<a name="cuda-prog-number-id213"> </a>



<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.12:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
       Demonstrate performance of matrix and vector computations on NVIDIA GPUs using MAGAMA BLAS library functions.<BR><BR>

<b> Download : </B> <a href="http://icl.cs.utk.edu/magma/" ><font color="blue"> http://icl.cs.utk.edu/magma/ </font></a>
 
 

<DIV ALIGN=right>
<A HREF="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>

<!-- ********************************* example 2.12ends ***************************** -->


<!-- ******************** example 2.13 starts ***************************** -->

<a name="cuda-prog-number-id214"> </a>



<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.13:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
       Demonstrate performance of  data-parallel algorithm primitives such 
as parallel prefix-sum (\93scan\94), parallel sort and parallel 
reduction (Primitives such as these are important building blocks for a wide variety of  data-parallel 
algorithms, including sorting, stream compaction, and building data structures such as  trees and 
summed-area tables) using CUDPP Library.<BR><BR>

<b> Refer : </B> <a href="http://gpgpu.org/developer/cudpp" ><font color="blue"> http://gpgpu.org/developer/cudpp</font></a>
 
 
</UL>
</TD>
</tr>
</tbody>
</table>


<!-- ************************* example 2.13 ends **************************** -->

<!-- ******************** example 2.14 starts *************************** -->

<a name="cuda-prog-number-id215"> </a>


<table border="0"  height="6">
<tbody>
     <tr>
     <td width="15%" height="2" valign="top">
 
     <b>  <font color = "red"> Example 2.14:  </font>  </b> </td>
    <td width="85%" height="2" valign="top">
       Demonstrate performance of sparse matrices computation using  NVIDIA CUDA CUSPARSE  library.<BR><BR>

<b> Refer : </B> <a href="./../gpu-comp-nvidia-cuda-pdf/NVIDIA_CUSPARSE_Library.pdf" ><font color="blue"> NVIDIA_CUSPARSE_Library.pdf</font></a>
 
 
<DIV ALIGN=right>
<A href="gpu-comp-nvidia-cuda-num-library.html"> 
        <IMG SRC="../gpu-comp-nvidia-cuda-images/up.gif" border=0 width="13" height="13"></A>
</DIV>
</UL>
</TD>
</tr>
</tbody>
</table>


<!-- ********************* example 2.14 ends *********************** -->


<!-- **********************  Table for codes ends ******************* -->

</TD></TR>
<!--  content of web page End here  --> 
 
                       
</TD></TR></TBODY></TABLE>

</TBODY></TABLE>



</TD></TR></TBODY></TABLE> 


      <TABLE  class=footarea cellSpacing=0 cellPadding=0 border=0 bordercolor=red>
        <TBODY>
        <TR>

          <TD class=footertext align=center>
           <A href="http://www.cdac.in" target=_blank><FONT color=blue size=2>
            Centre for Development of Advanced Computing </FONT></A> 
         </TD>

        

        </TR></TBODY></TABLE>


</TD></TR></TBODY></TABLE>

</TD></TR></TBODY></TABLE></BODY></HTML>
