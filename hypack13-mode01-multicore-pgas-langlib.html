<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">

<HTML>
<HEAD>
<TITLE> C-DAC,Pune : High-Perf. Comp. Frontier Technologies Exploration Group and
 CMSD, University of Hyderabad, Technology Workshop hyPACK (October 15-18), 2013 </TITLE>

<META http-equiv=Content-Type content="text/html; charset=iso-8859-1">

<meta name="Description" content="Center for Development of Advanced Computing (C-DAC) Pune and 

   Centre for Modelling Simulation and Design (CMSD), High-Performance Computing (HPC) Facility
   University of Hyderabad, Hyderabad are jointly organizing four days technology 
   workshop on   Hybrid Computing - Coprocessors &amp; Accelerators - 
   Power-aware Computing &amp;  Performance of  
  Application Kernels (hyPACK-2013)
  (Initiatives on Measurement Power Consumption &amp; Performance of Kernels"
    which is scheduled from October 15-18, 2013 at CMSD,
   High-Performance Computing (HPC) facility University of 
Hyderabad, Hyderabad.The hyPACK-2013 is designed four days for HPC GPU Cluster
 for Applications."/>

<meta name="KeyWords" content="Multi-Core, Parallel Processing,
 Software threading,GPGPU,GPU computing,MPI,OpenCL, Intel Xeon-Phi Coprocessor, 
NVIDIA -CUDA,AMD-APP Computing, Intel MIC, C-DAC workshops,OpenMP,Pthreads,Heterogenous Computing,Multi-Core tools,MultiCore 
Processors,GPU Programming, HPC GPU Cluster, 
Performance CDAC Technology training programme(S),Intel Software tools" />

<META id=Copyright content="Copyright (c) 2013,C-DAC." name=Copyright>

<META http-equiv=imagetoolbar content=no>

<LINK href="hypack13-files/hypack-main.css" 
type=text/css rel=stylesheet><LINK href="hypack13-files/hypack-home.css" type=text/css 
rel=stylesheet><LINK href="hypack13-files/hypack-schedule.css" rel=stylesheet>

<SCRIPT language=JavaScript src="hypack13-files/hypack-main.js" 
type=text/javascript></SCRIPT>

<META content="MSHTML 6.00.2900.5726" name=GENERATOR></HEAD>
<BODY style="MARGIN: 0px" leftMargin=0 topMargin=0 marginheight="0" 
marginwidth="0">

<TABLE class=container cellSpacing=0 cellPadding=0 border=0>
  <TBODY>
  <TR>
    <TD class=container>
      <TABLE class=header cellSpacing=0 cellPadding=0 border=0>
        <TBODY>
        <TR>
          <TD class=headerlogo>
           <A href="index.html"><IMG alt=hypack-2013
             src="hypack13-files/hypack-2013-header.jpg" border=0>
           </A>
       </TD>
 
     </TR>
     </TBODY>
     </TABLE>
      

<SCRIPT language=JavaScript1.2 type=text/javascript>

</SCRIPT>

     
    
  <TABLE class=mainmenubar cellSpacing=0 cellPadding=0>
        <TBODY>
        <TR>
          <TD align=middle>
            <TABLE cellSpacing=0 cellPadding=0>
              <TBODY>
 
	      <TR>

                <TD class=menu1><A class=menu1 id=mainmenurow1 
                  onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
       		  href="hypack13-about-overview.html">About</A></TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow2 
                  onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
                  href="hypack13-tech-prog-topics-overview.html">  Tech. Prog. </A></TD>
 
               
                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow3 
                  onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
                  href="hypack13-mode01-multicore-lab-overview.html">Muti-Core </A></TD>
                
               <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow4 
                  onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
                  href="hypack13-mode02-arm-proc-lab-overview.html"> ARM Proc</A></TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow5 
                  onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
                  href="hypack13-mode03-coprocessor-lab-overview.html">Coprocessors </A></TD>
                        
     
                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow6
                  onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
                  href="hypack13-mode04-gpgpu-lab-overview.html"> GPUs </A> </TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow7 
                  onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
                  href="hypack13-mode05-hpc-cluster-lab-overview.html"> HPC Cluster</A></TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow6
                  onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
                  href="hypack13-mode06-app-kernels-lab-overview.html"> App. Kernels</A> </TD>

                <TD class=menusep></TD>
                <TD class=menu1><A class=menu1 id=mainmenurow7 
                  onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
                  onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
                  href="hypack13-reg-overview.html">Registration </A></TD>

                                                          
</TR></TBODY></TABLE></TD></TR></TBODY>
	</TABLE>

      <DIV class=menu2>

 <!--   Sub menu for **** Row-1-About ****  start here -->

      <TABLE id=submenutab1 onMouseOver="javascript:hypackShowSubMenuDelay('1',1)" 
       style="VISIBILITY: hidden; MARGIN-LEFT: 0px; POSITION: absolute" 
       onmouseout="javascript:hypackHideSubMenuDelay('1',1)" cellSpacing=0 
       cellPadding=0 width=150>

       <TBODY>
       <TR>
       <TD class=menu2>


      <A class=menu2 id=submenurow1s1 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-overview.html"><B> Overview </B></A>
  
      <A class=menu2 id=submenurow1s2 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-venue.html"><B>  Venue : CMSD, UoH </B></A>

       <A class=menu2 id=submenurow1s3 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-keynote-invited-talks.html"><B>  Key-Note/Invited Talks </B> </A>

        <A class=menu2 id=submenurow1s4 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-faculty.html"><B>  Faculty / Speakers </B></A>

       <A class=menu2 id=submenurow1s5 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-proceedings.html"><B>   Proceedings </B></A>

	<A class=menu2 id=submenurow1s6 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-download-software.html"><B>  Downloads  </B> </A>
  
	<A class=menu2 id=submenurow1s7
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-past-workshops.html"><B>  Past Tech. Workshops </B></A>

       <A class=menu2 id=submenurow1s8 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-audience.html"><B> Target Audience </B></A>

       <A class=menu2 id=submenurow1s9 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-benefits.html"><B> Benefits</B></A>

	<A class=menu2 id=submenurow1s10 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-organisers.html"><B>  Organisers </B> </A>

        <A class=menu2 id=submenurow1s11 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-accommodation.html"><B>  Accommodation </B></A>

        <A class=menu2 id=submenurow1s12 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-local-travel.html"><B> Local Travel</B></A>

	<A class=menu2 id=submenurow1s13 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-sponsors.html"><B>  Sponsors </B></A>

        <A class=menu2 id=submenurow1s14 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-feedback.html"><B>  Feedback </B></A>

        <A class=menu2 id=submenurow1s15 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-acknowledgements.html"><B>  Acknowledgements </B> </A>

        <A class=menu2 id=submenurow1s16 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="hypack13-about-contact-address.html"><B>  Contact </B> </A>

        <A class=menu2 id=submenurow1s17 
            onmouseover="javascript:hypackShowSubMenuDelay('1', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('1', 1)" 
            href="index.html"><B>   Home  </B> </A>

 
      </TD></TR></TBODY></TABLE>

<!--   Sub menu for **** Row-1-About **** End  here --> 



<!--   Sub menu for **** Row-2-Topics of interest ****  start  here --> 

      <TABLE id=submenutab2 onMouseOver="javascript:hypackShowSubMenuDelay('2',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 60px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('2',1)" cellSpacing=0 
      cellPadding=0 width=150>
        <TBODY>
        <TR>
          <TD class=menu2>

          <A class=menu2 id=submenurow2s1 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-tech-prog-topics-overview.html"><B>  Topics of Interest </B></A>

          <A class=menu2 id=submenurow2s2 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-tech-prog-schedule.html"><B> Tech. Prog. Schedule</B></A>
   
	 <A class=menu2 id=submenurow2s3 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-mode01-multicore.html"><B>  Topic : Multi-Core </B></A>

         <A class=menu2 id=submenurow2s4 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-mode02-arm-proc.html"><B>  Topic : ARM Proc. </B></A>

         <A class=menu2 id=submenurow2s5 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-mode03-coprocessor.html"><B>  Topic : Coprocessors </B></A>

         <A class=menu2 id=submenurow2s6 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-mode04-gpgpu.html"><B>  Topic : GPGPUs </B></A>

         <A class=menu2 id=submenurow2s7 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-mode05-hpc-cluster.html"><B>  Topic : HPC  Cluster</B></A>

         <A class=menu2 id=submenurow2s8 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-mode06-app-kernels.html"><B>  Topic : App. Kernels.</B></A>
                    
         <A class=menu2 id=submenurow2s9
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-laboratory.html"><B>  Topic : Lab. Session</B></A>

         <A class=menu2 id=submenurow2s10 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="hypack13-topics-keynote-invited-talks.html"><B> Key-Note / Invited Talks</B> </A>

           
         <A class=menu2 id=submenurow2s11 
            onmouseover="javascript:hypackShowSubMenuDelay('2', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('2', 1)" 
            href="index.html"><B>    Home  </B> </A>
 
	
      </TD></TR></TBODY></TABLE>

<!--   Sub menu for **** Row-2-Topics of interest ***** End  here -->



<!--   Sub menu for **** Row-3 : Mode 1 (Multi-Cores): Hands-on ****  start here  -->

      <TABLE id=submenutab3 onMouseOver="javascript:hypackShowSubMenuDelay('3',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 200px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('3',1)" cellSpacing=0 
      cellPadding=0 width=150>

        <TBODY>
        <TR>
          <TD class=menu2>
        <A class=menu2 id=submenurow3s1 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-lab-overview.html"><B>   Mode-1 Multi-Core </B></A>

        <A class=menu2 id=submenurow3s2 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-memory-allocators.html"><B> Memory Allocators</B></A>

        <A class=menu2 id=submenurow3s3
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-openmp.html"><B>OpenMP  </B></A>

        <A class=menu2 id=submenurow3s4 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-intel-tbb.html"><B> Intel TBB </B></A>

        <A class=menu2 id=submenurow3s5 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-pthreads.html"><B>  Pthreads  </B></A>
	
       <A class=menu2 id=submenurow3s6 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-java-threads.html"><B> Java - Threads  </B></A>

       <A class=menu2 id=submenurow3s7 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-charmplusplus.html"><B> Charm++ Prog. </B></A>

        <A class=menu2 id=submenurow3s8
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-mpi.html"><B> Message Passing (MPI) </B></A>
 
        <A class=menu2 id=submenurow3s9
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-mpi-openmp.html"><B>  MPI - OpenMP</B></A>
  
       <A class=menu2 id=submenurow3s10
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-mpi-tbb.html"><B>  MPI - Intel TBB </B></A>
 
       <A class=menu2 id=submenurow3s11
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-mpi-pthreads.html"><B>  MPI - Pthreads </B></A>

        <A class=menu2 id=submenurow3s12 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-compiler-tune-perf.html"><B> Compilers - Opt. Features </B></A>

        <A class=menu2 id=submenurow3s13 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-perf-math-lib.html"><B> Threads-Perf. Math. Lib.</B></A>

        <A class=menu2 id=submenurow3s14 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-software-tools.html"><B>  Threads-Prof. &amp; Tools</B></A>

       <A class=menu2 id=submenurow3s15 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-threads-io-perf.html"><B>Threads - I/O Perf. </B></A>
  
        <A class=menu2 id=submenurow3s16 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-pgas-langlib.html"><B> PGAS : UPC / CAF/ GA</B></A>

        <A class=menu2 id=submenurow3s17
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="hypack13-mode01-multicore-power-perf.html"><B> Power &amp; Perf.  </B></A>

       <A class=menu2 id=submenurow3s18 
            onmouseover="javascript:hypackShowSubMenuDelay('3', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('3', 1)" 
            href="index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>

<!--   Sub menu **** Row-3 : Mode 1 (Multi-Cores ) : Hands-on ****  End here  -->



<!--   Sub menu for **** Row-4 : Mode 2 (ARM Processor) Hands-on ****  start here  -->

      <TABLE id=submenutab4 onMouseOver="javascript:hypackShowSubMenuDelay('4',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 200px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('4',1)" cellSpacing=0 
      cellPadding=0 width=150>

        <TBODY>
        <TR>
          <TD class=menu2>
        <A class=menu2 id=submenurow4s1 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="hypack13-mode02-arm-proc-lab-overview.html"><B>   Mode-2 ARM  </B></A>

        <A class=menu2 id=submenurow4s2 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="hypack13-mode02-arm-proc-prog-env.html"><B> Prog. Env </B></A>
      
       <A class=menu2 id=submenurow4s3 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="hypack13-mode02-arm-proc-benchmarks.html"><B> Benchmarks</B></A>

       <A class=menu2 id=submenurow4s4
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="hypack13-mode02-arm-proc-power-perf.html"><B> Power &amp; Perf.  </B></A>

       <A class=menu2 id=submenurow4s5 
            onmouseover="javascript:hypackShowSubMenuDelay('4', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('4', 1)" 
            href="index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>


<!--   Sub menu **** Row-4 : Mode 2 (ARM Processor) : Hands-on ****  End here  -->




<!--   Sub menu for **** Row-5 : Mode 3 (Coprocessor) Hands-on ****  start here  -->

      <TABLE id=submenutab5 onMouseOver="javascript:hypackShowSubMenuDelay('5',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 200px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('5',1)" cellSpacing=0 
      cellPadding=0 width=150>

        <TBODY>
        <TR>
          <TD class=menu2>
        <A class=menu2 id=submenurow5s1 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="hypack13-mode03-coprocessor-lab-overview.html"><B>   Mode-3 Coprocessors </B></A>

        <A class=menu2 id=submenurow5s2 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="hypack13-mode03-coprocessor-arch-software.html"><B> Arch. Software </B></A>

        <A class=menu2 id=submenurow5s3 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="hypack13-mode03-coprocessor-compiler-vect.html"><B> Compiler &amp; Vect. </B></A>
     
        <A class=menu2 id=submenurow5s4 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="hypack13-mode03-coprocessor-prog-env.html"><B> Prog. Env. </B></A>

        <A class=menu2 id=submenurow5s5 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="hypack13-mode03-coprocessor-benchmarks.html"><B> Benchmarks</B></A>

        <A class=menu2 id=submenurow5s6
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="hypack13-mode03-coprocessor-power-perf.html"><B> Power &amp; Perf.  </B></A>

        <A class=menu2 id=submenurow5s7 
            onmouseover="javascript:hypackShowSubMenuDelay('5', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('5', 1)" 
            href="index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>


<!--   Sub menu **** Row-5 : Mode 3 (Coprocessor) : Hands-on ****  End here  -->



<!--   Sub menu for **** Row-6 : Mode 4 (GPGPUs): Hands-on **** Start here  -->

      <TABLE id=submenutab6 onMouseOver="javascript:hypackShowSubMenuDelay('6',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 285px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('6',1)" cellSpacing=0 
      cellPadding=0 width=150>
        <TBODY>
        <TR>
          <TD class=menu2>

	<A class=menu2 id=submenurow6s1 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="hypack13-mode04-gpgpu-lab-overview.html"><B> Mode-4 GPGPUs  </B></A>

	<A class=menu2 id=submenurow6s2 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="hypack13-mode04-gpgpu-nvidia-gpu-cuda.html"><B>NVIDIA - CUDA/OpenCL </B></A>


	<A class=menu2 id=submenurow6s3 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="hypack13-mode04-gpgpu-amd-opencl.html"><B>AMD  APP - OpenCL</B></A>


	<A class=menu2 id=submenurow6s4 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="hypack13-mode04-gpgpu-opencl.html"><B> GPGPUs - OpenCL </B></A>

        <A class=menu2 id=submenurow6s5 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="hypack13-mode04-gpgpu-power-perf.html"><B> GPGPUs : Power &amp; Perf. </B></A>

        <A class=menu2 id=submenurow6s6 
            onmouseover="javascript:hypackShowSubMenuDelay('6', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('6', 1)" 
            href="index.html"><B>   Home  </B> </A>


	   </TD></TR> </TBODY></TABLE>

<!--  Sub menu for **** Row-6 : Mode-4 (GPGPUs) : Hands-on **** End here  -->



<!--   Sub menu for **** Row-7 : Mode-5 (HPC GPU Cluster): Hands-on  **** start  here -->

      <TABLE id=submenutab7 onMouseOver="javascript:hypackShowSubMenuDelay('7',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 365px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('7',1)" cellSpacing=0 
      cellPadding=0 width=150>


        <TBODY>
        <TR>
          <TD class=menu2>

        <A class=menu2 id=submenurow7s1 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="hypack13-mode05-hpc-cluster-lab-overview.html"><B>  Mode-5  HPC Cluster </B></A>
        
        <A class=menu2 id=submenurow7s2 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="hypack13-mode05-hpc-message-passing-cluster.html"><B> HPC  MPI   Cluster   </B></A>

	<A class=menu2 id=submenurow7s3
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="hypack13-mode05-hpc-gpu-cluster-nvidia-cuda.html"><B> GPU Cluster - NVIDIA   </B></A>

        <A class=menu2 id=submenurow7s4 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="hypack13-mode05-hpc-gpu-cluster-amd-opencl.html"><B>GPU Cluster - AMD APP </B></A>


        <A class=menu2 id=submenurow7s5 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="hypack13-mode05-hpc-intel-coprocessor-cluster.html"><B> Cluster - Intel Coprocessors </B></A>

        <A class=menu2 id=submenurow7s6 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="hypack13-mode05-hpc-cluster-power-perf.html"><B>  Cluster- Power &amp; Perf.  </B> </A>

        <A class=menu2 id=submenurow7s7 
            onmouseover="javascript:hypackShowSubMenuDelay('7', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('7', 1)" 
            href="index.html"><B>  Home  </B> </A>
      
	</TD></TR>
        </TBODY>
        </TABLE>


<!--   Sub menu for **** Row-7 : MODe-5 : (HPC GPU Cluster) Hands-on ****  End  here -->



<!--   Sub menu for **** Row-8 :Mode-6 Application  program  **** start here -->


      <TABLE id=submenutab8 onMouseOver="javascript:hypackShowSubMenuDelay('8',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 510px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('8',1)" cellSpacing=0 
      cellPadding=0 width=150>
        <TBODY>
        <TR>
          <TD class=menu2>
 
	 <A class=menu2 id=submenurow8s1 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-app-kernels-lab-overview.html"><B> Mode-6 App. Kernels </B></A>
                  
	<A class=menu2 id=submenurow8s2 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-pdesolvers-fdm-fem.html"><B>  PDE Solvers : FDM/FEM  </B></A>

        <A class=menu2 id=submenurow8s3 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-image-processing-fft.html"><B>  Image Processing - FFT </B></A>    

         <A class=menu2 id=submenurow8s4
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-phys-monte-carlo.html"><B> Monte Carlo Methods </B> </A>

     	 <A class=menu2 id=submenurow8s5 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-string-srch.html"><B>  String Srch. </B></A>
    

     	 <A class=menu2 id=submenurow8s6 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-seq-analysis.html"><B>  Seq. Analy.</B></A>
       
         <A class=menu2 id=submenurow8s7
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-video-processing.html"><B> Video Process. </B> </A>

        <A class=menu2 id=submenurow8s8 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-intrusion-detection-sys.html"><B>  Intr. Detcn. Sys  </B> </A>

        <A class=menu2 id=submenurow8s9 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="hypack13-mode06-app-kernels-power-perf.html"><B>  App. Power &amp; Perf.  </B> </A>

        <A class=menu2 id=submenurow8s10 
            onmouseover="javascript:hypackShowSubMenuDelay('8', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('8', 1)" 
            href="index.html"><B>   Home  </B> </A>


       </TD></TR></TBODY></TABLE>

<!--   Sub menu for **** Row-8 :Mode-6 Application Program **** End here -->


<!--  Sub menu for **** Row-9-Registration **** Start here  -->

      <TABLE id=submenutab9 onMouseOver="javascript:hypackShowSubMenuDelay('9',1)" 
      style="VISIBILITY: hidden; MARGIN-LEFT: 610px; POSITION: absolute" 
      onmouseout="javascript:hypackHideSubMenuDelay('9',1)" cellSpacing=0 
      cellPadding=0 width=150>

      <TBODY>
      <TR>
      <TD class=menu2>

      <A class=menu2 id=submenurow9s1 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="hypack13-reg-overview.html"><B> Reg. Overview</B></A>
           
      <A class=menu2 id=submenurow9s2 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="hypack13-reg-private-sector.html"><B>Pvt. Sector</B></A>

      <A class=menu2 id=submenurow9s3 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="hypack13-reg-govt-public-sector.html"><B>Pub. Sector</B></A>

      <A class=menu2 id=submenurow9s4 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="hypack13-reg-govt-academic-staff.html"><B>Govt. Acad. Staff </B></A>

      <A class=menu2 id=submenurow9s5 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="hypack13-reg-students.html"><B>Students Reg. </B></A>

      <A class=menu2 id=submenurow9s6
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="hypack13-reg-online-registration.html"><B>On-line Reg.</B></A>
 
      <A class=menu2 id=submenurow9s7 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
             href="hypack13-reg-accommodation.html"><B>Accommodation </B></A>

      <A class=menu2 id=submenurow9s8 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="hypack13-reg-contact-address.html"><B>Contact</B></A>

       <A class=menu2 id=submenurow9s9 
            onmouseover="javascript:hypackShowSubMenuDelay('9', 1)" 
            onmouseout="javascript:hypackHideSubMenuDelay('9', 1)" 
            href="index.html"><B>  Home  </B> </A>

      </TD></TR></TBODY></TABLE>

  <!--   Sub menu for  **** Row-9-Registration **** End here  -->


  </DIV>

<!--  *** left section code for about link start here ***  -->

   
     <INPUT id=menuval 
      type=hidden name=menuval> <INPUT id=menuval2 type=hidden name=menuval2> 
      <TABLE class=mainctnt cellSpacing=0 cellPadding=0 border=0>
        <TBODY>
        <TR>
          <TD class=mainctntcell>
            <TABLE cellSpacing=0 cellPadding=0 border=0>
              <TBODY>
              <TR>
                <TD class=leftmenu><BR>
    
            <A class=menul
	       href="hypack13-mode01-multicore-lab-overview.html">
               &#149; Mode-1 Multi-Core  </A>
            
	   <A class=menul
	      href="hypack13-mode01-multicore-memory-allocators.html">
              &#149;  Memory Allocators</A>
            
	   <A class=menul  
              href="hypack13-mode01-multicore-openmp.html">
              &#149; OpenMP</A>

	   <A class=menul  
              href="hypack13-mode01-multicore-intel-tbb.html">
              &#149; Intel TBB </A>

           <A class=menul
              href="hypack13-mode01-multicore-pthreads.html">
              &#149; Pthreads</A>
              
           <A class=menul
	      href="hypack13-mode01-multicore-java-threads.html">
              &#149; Java - Threads</A>

           <A class=menul
	      href="hypack13-mode01-multicore-charmplusplus.html">
              &#149; Charm++ Prog.</A>
          
	   <A class=menul
              href="hypack13-mode01-multicore-mpi.html">
              &#149; Message Passing (MPI)</A>
              
           <A class=menul 
	      href="hypack13-mode01-multicore-mpi-openmp.html">
              &#149; MPI - OpenMP</A>

           <A class=menul 
	      href="hypack13-mode01-multicore-mpi-tbb.html">
              &#149; MPI - Intel TBB</A>  
        
           <A class=menul 
	      href="hypack13-mode01-multicore-mpi-pthreads.html">
              &#149; MPI - Pthreads</A> 

	   <A class=menul
	      href="hypack13-mode01-multicore-compiler-tune-perf.html">
              &#149; Compiler Opt. Features</A>
             
	   <A class=menul 
	      href="hypack13-mode01-multicore-perf-math-lib.html">
              &#149; Threads-Perf. Math.Lib. </A>

           <A class=menul
	      href="hypack13-mode01-multicore-software-tools.html">
              &#149; Threads-Prof. &amp; Tools </A>
  
           <A class=menul
	      href="hypack13-mode01-multicore-threads-io-perf.html">
              &#149; Threads-I/O Perf. </A>

              <!-- ** -->
              <A class=menulslct
	       href="hypack13-mode01-multicore-pgas-langlib.html">
               &#149; PGAS : UPC / CAF / GA </A>
               <!-- ** -->

           <A class=menul
	      href="hypack13-mode01-multicore-power-perf.html">
              &#149; Power-Perf.   </A>
 
          <A class=menul 
	      href="index.html">
              &#149; Home</A>


<!-- ****************** left section code for about link End  here ************* -->
	
		 <BR>
                  <DIV 
                  style="BACKGROUND: url(images/) no-repeat 100% 100%; WIDTH: auto; HEIGHT: 300px"></DIV><BR><BR><BR><BR></TD>
                

 <TD class=rightctnt> 



<TABLE cellSpacing=0 cellPadding=0 border=0>
 <TBODY>

<!--  content of web page start here  --> 

<TR>
<TD>


<H1> hyPACK-2013 :  Mode-1 Partitioned Global Address Space Prog. Model  (PGAS) </H1> <BR> 

<table cellSpacing=0 cellPadding=0  border=0 >
<tbody>
<tr>
<td>

 <P align="justify"> <span class="content" >

Parallel, multithreaded programs are becoming increasingly prevalent. 
Parallel Computing is moving into a high-profile, mainstream role, and the delivery 
of effective parallel programming models is a high priority ask. 

Shared memory and Distributed memory models are two well known classification of parallel hardware
 architecture model.  

Parallel programming Model  introduces a new concept of exploiting the resources of Multiple cores. 
Using the resources of all the cores and thereby reducing the time complexity is the main aim of multicore 
Programming model. Some of the  desirable features for a parallel programming model are: i) ease of use, 
so users are productive; ii) expressiveness, so programmers can code a wide range of algorithms; 
iii) high-performance, so parallel codes utilize efficiently the capabilities of a parallel system of choice, 
iv) performance portability, so programmers can write their code once and achieve good performance on the 
widest possible range of parallel architectures and  V) preserve their expensive source code investment 
and easily target both multi-core CPUs and the latest GPUs and cluster of multi-core processors with GPUs.  
 Four important parallel programming models are in use : <BR> 
 
</span> </p>

 <ul>

 <span class = "content">

   <li> 
       Distributed Parallel Programming Model
   </li>

   <li> 
       Shared Parallel Programming Model
   </li>

   <li> 
 	Distributed and Shared Parallel programming Model (DSM), also called as PGAS.  
   </li>

   <li> 
	Hybrid Parallel Programming Model
   </li>

</span>

</ul>

<p align="justify"> <span class="content">


Moving into the future, it is expected that each node into a cluster system would be a many-core system.
 Developers needs parallel programming paradigms that provides high level of abstraction and efficient parallel 
coding techniques.  A breif summary of most popular shared and distributed 
memory models are summarised below. </span>
</p>
</td> 
</tr> 
</tbody>
</table>
<!---------------------- Sub-title Starts topics here-------------------------->

<table cellSpacing=0 cellPadding=0  border=0 >
<tbody>
 <tr>
 <td>
 <P align="justify"> <span class="content">
   
  
  <a href="#dist-sharedmem">
  <font size="2" face="Arial" color="blue"> <B> Distributed Memory  Model </b> </font> </a> 
 <BR> <BR> 


   <a href="#shared-mem-model"> 
   <font size="2" face="Arial" color="blue"> <B> Shared Memory  Model : </b>  </font>  </a>
   &nbsp; &nbsp;   

  <font size="2" face="Arial" color="black"> <b> (</b>  </font>  

  <a href="#shared-mem-openmp">
  <font size="2" face="Arial" color="blue"> <B> OpenMP  </b>  </font> </a> 
  &nbsp; &nbsp; &nbsp;  


  <a href="#shared-mem-tbb">
  <font size="2" face="Arial " color="blue"> <B> Intel TBB </b>  </font> </a> 
  &nbsp; &nbsp;  


<a href="#shared-mem-pthreads">
  <font size="2" face="Arial " color="blue"> <B> POSIX Threads  </b>  </font> </a> 

  
<font size="2" face="Arial" color="black"> <b> )</b>  </font>  

  <BR> <BR>

  <a href="#dist-hybrid-mem-model">
  <font size="2" face="Arial" color="blue"> <B> Hybrid Memory  Model   </b>    </font> </a> 

<BR> <BR>

  <a href="#dist-shared-mem-model-pgas">
  <font size="2" face="Arial" color="blue"> <B> Distributed Shared Memory  Model  (DSM) </b>    </font> </a> 
     
<font size="2" face="Arial" color="black"> <b> also called as </b>   </font> 

  <a href="#dist-shared-mem-model-pgas">
  <font size="2" face="Arial" color="blue"> <B> PGAS </b>    </font> </a> 
<BR> <BR>

<font size="2" face="Arial" color="black"> <b> PGAS (</b></font>  

  <a href="#dist-shared-mem-upc">
  <font size="2" face="Arial" color="blue"> <B> UPC</b></font> </a> 
  &nbsp; &nbsp;   


  <a href="#dist-shared-mem-caf">
  <font size="2" face="Arial " color="blue"> <B> CAF</b></font></a> 
  &nbsp; &nbsp;  

 <a href="#dist-shared-memoryx10">
  <font size="2" face= "Arial" color="blue"> <B> X10 </b></font></a>
&nbsp; &nbsp;

  <a href="#dist-shared-mem-titanium">
  <font size="2" face="Arial " color="blue"> <B> Titanium</b></font></a>
&nbsp; &nbsp; 

<a href="#dist-shared-mem-ga">
  <font size="2" face="Arial " color="blue"> <B> Global Arrays</b></font></a>
&nbsp; &nbsp;



<a href="#dist-shared-mem-chapel">
  <font size="2" face="Arial " color="blue"> <B> Chapel</b></font></a>
&nbsp; &nbsp;
  
<a href="#dist-shared-mem-proglib">
  <font size="2" face="Arial " color="blue"> <B> Other Prog. Lib.</b></font></a>

<font size="2" face="Arial" color="black"><b>)</b></font>  

  <BR> <BR>

<a href="#pgas-hands-on-session-topics">
  <font size="2" face="Arial " color="blue"> <B> PGAS Hands-on Lab. Overview </b></font></a>
&nbsp; &nbsp; <BR>


<HR>

<p align = "right"> <font color = "red"> 
<span class ="content"> <i> <B> Courtesy  :  </b> </i> </font>
<a  href="http://pgas11.rice.edu"  target="_blank" > <font color = "blue"> PGAS 2011</font></a>,
<a  href="http://x10-lang.org"  target="_blank" > <font color = "blue">  IBM X10 </font></a>,
<a  href="http://chapel.cray.com"  target="_blank" >  <font color = "blue"> Chapel</font></a>,
<a  href="http://www.upcworld.org" target="_blank" > <font color = "blue">UPC consortium</font></a>,  

<a  href="http://upc.gwu.edu"  target="_blank" > <font color = "blue"> UPC Lanugage Specification</font></a> <BR>
<a  href="http://titanium.cs.berkeley.edu" target="_blank" > <font color = "blue"> Titanium</font></a>, 
<a  href="http://caf.rice.edu"  target="_blank" > <font color = "blue"> Coarray Fortran (CAF)</font></a>,
<a  href="http://www.emsl.pnl.gov/docs/global/"  target="_blank" > <font color = "blue"> Global Arrays ToolKit</font></a>,
<a  href="http://www.ibm.com" target="_blank" > <font color = "blue">IBM</font></a>,
<a  href="http://www.shmem.org" target="_blank" > <font color = "blue">SGI SHMEM</font></a>,
<a  href="http://www.sgi.com" target="_blank" > <font color = "blue">SGI </font></a> <BR> <BR>
  
</span> </p>

<!-- reference start here -->

<span class ="content">  <font size = 2 face="Arial" color="#FF0011"> 
<b> <I>  References : </i>   </font>  </b> </a></B> 



<a href="./reference-hypack-2013/reference-overview-hypack13-mode01-pgas.html#mode01-pgas-upc-ref"> 
 <font size="2" face="Arial" color="blue"><B> UPC</b>  </font> </a> 
  &nbsp;  

<a href="./reference-hypack-2013/reference-overview-hypack13-mode01-pgas.html#mode01-pgas-caf-ref"> 
 <font size="2" face="Arial" color="blue"><B> CAF</b>  </font> </a> 
  &nbsp;  

<a href="./reference-hypack-2013/reference-overview-hypack13-mode01-pgas.html#mode01-pgas-titanium-ref"> 
 <font size="2" face="Arial" color="blue"><B> Titanium</b>  </font> </a> 
  &nbsp;  

<a href="./reference-hypack-2013/reference-overview-hypack13-mode01-pgas.html#mode01-pgas-ga-ref"> 
 <font size="2" face="Arial" color="blue"><B> Global Arrays</b>  </font> </a> 
   &nbsp;

<a href="./reference-hypack-2013/reference-overview-hypack13-mode01-pgas.html#mode01-pgas-x10-ref"> 
 <font size="2" face="Arial" color="blue"><B> X10 (IBM)</b>  </font> </a> 
    &nbsp; &nbsp;

<a href="./reference-hypack-2013/reference-overview-hypack13-mode01-pgas.html#mode01-pgas-chapel-ref"> 
 <font size="2" face="Arial" color="blue"><B> Chapel (Cray)</b>  </font> </a>
&nbsp;&nbsp;

<a href="./reference-hypack-2013/reference-overview-hypack13-mode01-pgas.html#mode01-pgas-lib-ref"> 
 <font size="2" face="Arial" color="blue"><B> PGAS Lib.</b>  </font> </a> 
 <BR>


</span> </p>

<BR>  

  
</TD></TR>
</TBODY>
</TABLE>


<HR>
 


<!-- ****************************** Distributed Memory Model  Starts ************************* -->


<a name="dist-sharedmem"> </a>

<TABLE cellSpacing=0 cellPadding=0  border=0> 
<TBODY>


<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b>Distributed Memory  Model  </b> 
</font> 
</DIV


</TD>
</TR> 


<TR> 
<TD>


<BR>

<P align = "justify"> <span class="content">  

In the distributed memory model, the entire processors unit has their own local memory and they communicate through 
high speed networks. Here a cluster of nodes, each node with multiple cores communicates with each other through 
explicit message passing mechanisms. To facilitate this there are many Vendor supplied libraries like MPI 
(Message Passing Interface). This is an SPMD (Single Program Multiple Data) Model , where the work is 
distributed between a number of processes running on the cluster of nodes. The main drawbacks associated with 
this model are , large overheads when we need to send large amount of data , and every Process has a limit to 
its Private memory. 
MPI programming model is commonly used for HPC Clusters, and it has proven highly scalable and highly 
successful for scientific calculations for over a decade. It is used on clusters of computers, MPP supercomputers,
 and even on desktops with multiple CPUs. Independent images of an application run as separate processes on each CPU.
<BR> <BR>

 The MPI-1 standard provides for two-sided messaging where communicating pairs of processes call Send and Recv to 
transmit a message, as well as a variety of powerful and efficient collective operations. The MPI-2 standard  added 
support for one-sided messaging
that allows processes to perform remote access to exposed regions of memory. In this model, processes collectively 
expose windows of memory for remote access. The window may then be accessed in
either active or passive target mode. Under the active target mode,
the host explicitly synchronizes its window between accesses; under the passive target mode, remote processes may 
access the window without any explicit interaction from the host.

</span> </p>

<ul>

 
<li> <P align = "justify"> <span class="content"> 
<I> For High-Performance Computing (HPC),  clusters are being used for HPC, which are composition of nodes that are connected over a high-bandwidth network. HPC is a distributed and complex programming environment that requires sophisticated programming paradigms and  tools. In the past, each node in an HPC cluster had a single or multi-core node.  <BR> </span> </p> 
</li>

</ul>

  <div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>


</TD>
</TR>
</TBODY> 
</TABLE> 

<!-- ****************************** Distributed Memory Model  Ends ************************* -->



<!-- ****************** Shared Memory Model starts ************************* -->

<a name="shared-mem-model"> </a>

<TABLE cellSpacing=0 cellPadding=0 > 
<TBODY>

<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b>Shared Memory Model  </b> 
</font> 
</DIV


</TD>
</TR> 



<TR>
<TD>

<BR>

 <P align= "justify"><span class="content" >


 Shard memory models are usually called as tightly tightly-coupled multiprocessor machines in which all the cores in a shared memory model are connected to a single global memory.   
Symmetric multiprocessing (SMP) designs have been long implemented using discrete CPUs, 
the issues regarding implementing the architecture and supporting it in software are well known. 
In addition to operating system (OS) support, adjustments to existing software are required to 
maximize utilization of the computing resources provided by multi-core processors.
 Also, the ability of multi-core processors to increase application performance depends 
on the use of multiple threads within applications. <BR> <BR>
The most important challenge in shared-address-space programming is the decomposition of a single 
application into several, dependent and interacting tasks. The efficiency of the parallel program
 is highly dependent on this decomposition step: it determines the synchronization and 
communication overhead. 

Other challenges are synchronization and communication between parallel threads. 
Synchronizing parallel threads is a tedious task: synchronizing too often leads to 
inefficient program execution but not enough synchronization can lead to incorrect results 
due to the data races or condition hazards. Faulty synchronization can lead to deadlocks in
the Shared-address-spcae programming. The shared memory model is quite suitable to Pthread Programming and the users should 
understand concepts of 
synchronization, critical section and deadlock conditions. 
Synchronization 
is an enforcing mechanism used to impose constraints on the order of execution of threads. <BR> <BR>
 The features of the Shared 
memory model : </span> </p>


<ul>
 <P align=justify><span class="content" >

     <li> All threads have access to the same global, shared memory </li>

     <li> Threads also have their own private data </li>

     <li> Programmers are responsible for synchronizing access (protecting) globally shared data.</li>
</span> </p>

</ul>


<P align=justify><font class="content" >

   Shared-memory
          systems typically provide both static and dynamic process creation.
          That is, processes can be created at the beginning of program
          execution by a directive to the operating system, or they can be
          created during the execution of the program. The best-known dynamic
          process creation function is fork. A typical implementation will allow
          a process to start another, or child, process by a fork. Three
          processes typically manage coordinating among processes in shared
          memory programs. The starting, or a parent, process can wait for the
          termination of the child process by calling join. The second prevents
          processes from improperly accessing shared resources. The third
          provides a means for synchronizing the processes. <BR> <BR>


      The shared-memory model is similar to the data-parallel model.
          It has a single address (global naming) space.
         It is similar to the message-passing model in that it is
          multi-threading and synchronous. However,
          data reside in a single, shared address space, thus does not have to
          be explicitly allocated. Workload
          can be either explicitly or implicitly allocated. Communication is
          done implicitly through shared reads and writes of variables.
          However, synchronization is explicit.
         <BR> <BR>


          Shared variable programs are multi threaded and asynchronous; require
          explicit synchronizations to maintain correct execution order among
          the processes. Parallel programming based on the shared memory model
          has not progressed as much as message passing parallel programming.
          An indicator is the lack of a widely accepted standard such as
          MPI or PVM for message passing. The
          current situation is that shared-memory programs are written in a
          platform specific language for multiprocessors (mostly SMPs and PVPs).
          Such programs are not portable even among multiprocessors, not
          to mention multicomputers (MPPs and clusters). Three platform
          independent shared memory-programming models are X3H5, Pthreads, Intel TBB, and
          OpenMP.
</span> </p>
       
<div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>

 
</TD>
</TR>

</TBODY> 
</TABLE> 

<!-- ******************  Shared Memory Model ends ***************** -->


<!-- ******************  Shared Memory Model OpenMP start here ****************** -->

<a name="shared-mem-openmp">   </a>

<TABLE cellSpacing=0 cellPadding=0 border=0> 
<TBODY>

<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b>Shared Memory Model-OpenMP  </b> 
</font> 
</DIV>
</TD>
</TR> 


<BR>

<TR>
<TD>

<BR> 
 <P align=justify><span class="content" >



OpenMP is a Shared memory programming Model, where a program executes in a serial execution mode , but at some points of program (eg:loops) the main thread executing in serial mode, Creates required number of threads and  distributes the work between them and joins them after completing the work.
It  is an Application Program Interface (API) that may be used 
            to explicitly direct multi-threaded, shared memory parallelism. It 
            is a specification for a set of compiler directives, library routines 
            and environment variables that can be used to specify shared memory 
            parallelism in Fortran and C/C++ programs. The OpenMP is a shared
          memory standard supported by a group of hardware and software
          vendors. It
          is comprised of three primary API components: <BR>  


          
          <UL>
            <LI> Compiler Directives&nbsp</LI>
            <LI> Runtime Library Routines</LI>
            <LI> Environment Variables</LI>
          </UL>


          OpenMP is portable and the API is specified for C/C++ and Fortran. 
            Multiple platforms have been implemented including most Unix platforms 
            and Windows NT. It is jointly defined and endorsed by a group of major 
            computer hardware and software vendors. 

            The goal is to define standardization and  provide a standard among a 
           variety of shared memory 
            architectures/platforms.   Also, establish a simple and limited set of 
               directives for 
            programming shared memory machines to achieve  significant parallelism 
           that can be 
            implemented by using just 3 or 4 directives.
         </span> </p>

  

<div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>

</TD>
</TR>

</TBODY> 
</TABLE> 


<!-- ******************* Shared Memory Model OpenMP Ends here **************** -->


<!-- *********************** Shared Memory Intel TBB  starts ********************* -->


<a name="shared-mem-tbb"> </a>


<TABLE cellSpacing=0 cellPadding=0  border=0> 
<TBODY>

<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b>Shared Memory Model-Intel TBB   </b> 
</font> 
</DIV>
</TD> 
</TR> 

<TR>
<TD>

 <P align = "justify"> <span class="content"> 
  

Intel Threading Building Blocks (Intel TBB), based on threading model.  
Threading Building Blocks represents a higher-level, task-based parallelism that abstracts platform details and 
threading mechanisms for performance and scalability. 
Threading Building Blocks helps you create applications that reap the benefits of new processors with more and
 more cores as they become available.
Intel Threading Building Blocks uses templates for common parallel iteration patterns, enabling programmers to attain increased speed from multiple processor cores without having to be experts in synchronization, load balancing, and cache optimization.
TBB  is a library that helps you leverage multi-core processor performance without having to be a threading expert. 

It has two basic Components Task Scheduler
 and Memory allocator. TBB uses its own memory allocator that allocates memory directly from the Heap, 
for fast and feasible operations. Work in TBB is termed as tasks and these tasks are scheduled by task Scheduler. 
TBB task Scheduler implements "Work-Stealing". Initially entire work is initially being distributed between each
 core, if a core completes its work prior to other cores, some work on other core is transferred to this core, 
thus making all the cores busy.
</span> </p>

<div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>

</TD> 
</TR> 
</TBODY> 
</TABLE> 

<!-- ********************** Shared Memory - Intel TBB  ends ******************** -->


<!-- *********************** Shared Memory POSIX Threads  starts ********************* -->


<a name="shared-mem-pthreads"> </a>


<TABLE cellSpacing=0 cellPadding=0  border=0> 
<TBODY>

<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b>Shared Memory Model-POSIX Threads </b> 
</font> 
</DIV>
</TD> 
</TR> 

<TR>
<TD>

 <P align = "justify"> <span class="content"> 
  

POSIX threads or Pthreads is a portable threading library, which provides consistent programming interface across 
 multiple operating systems. Pthreads is emerged as a standard threading interface for Linux and Unix
 platforms.

     Pthreads are defined as a set of C language programming types and procedure calls, implemented with a pthread.h header/include file and a 
thread library - though the this library may be part of another library, such as libc.
 A number of vendors provide vendor specific thread APIs. More core Pthreads functions on thread
 creation and destruction, synchronization and other thread features. In shared memory multiprocessor 
 architectures, such as SMPs, threads can be used to implement parallelism.
It specifies API to handle most of actions required by 
threads.It is a library that has  standardized functions for using threads across different platforms.
In general though, in order for a program to take advantage of Pthreads, it must be able to be organized into discrete, 
independent tasks which can execute concurrently.

The concepts used in this "Pthreads on Multi-Cores" are largely 
independent of the API and can be used for programming with other thread APIs (Windows NT threads, 
Solaris threads, Java threads etc.. )

Programs having the following characteristics may be well suited for pthreads: </span> </p>

<ul>
<blockquote>
 <P align=justify><span class="content" >
 <li>  Work that can be executed, or data that can be operated on, by multiple tasks simultaneously </li>
  <li>   Block for potentially long I/O waits </li>
  <li> Use many CPU cycles in some places but not others </li>
   <li> Must respond to asynchronous events </li>
  <li>  Some work is more important than other work (priority interrupts) </li> 
</span> </p>
</blockquote>
</ul>

</span> </p>

<div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>

</TD> 
</TR> 
</TBODY> 
</TABLE> 

<!-- ********************** Shared Memory - POsIX Threads  ends ******************** -->




<!-- *********************** Hybrid  Memory Model   starts ********************* -->


<a name="dist-hybrid-mem-model"> </a>


<TABLE cellSpacing=0 cellPadding=0  border=0> 
<TBODY>

<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b> Hybrid  Memory Model </b> 
</font> 
</DIV>
</TD> 
</TR> 

<TR>
<TD>

 <P align = "justify"> <span class="content"> 
  
In hybrid Memory models, sometimes called mixed-mode programming, that combine
two different models into the same program. This model is typically used on Message Passing clusters
of shared memory machines, where a shared memory model is used within a node and
a message passing model is used to exchange data between nodes. Examples of hybrid
models include OpenMP with MPI or Pthreads with MPI or Intel TBB with MPI and HPF with MPI.
For large number of cores on a single node, if application has huge data parallelism, the model 
offers performance and scalability. 

Using a shared memory model on a node avoids the overhead and data replication from
using explicit message passing, but at the cost of greater complexity. Mixed-mode programming
does not guarantee the benefits of the two models being used. In some cases, a
mixed-mode code can run slower than a single-mode code. For example, multiple threads
within an OpenMP or Pthreads process may have to synchronize on MPI calls, eliminating the opportunity
to overlap computation and communication. It may also be non-trivial to break
single-level parallelism in MPI codes into multi-level parallelism needed for a hybrid approach.
For certian class of applications the issues such as  multi-threaded I/O with MPI I/O 
require special care. 


</span> </p>

<div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>

</TD> 
</TR> 
</TBODY> 
</TABLE> 

<!-- ********************** Hyrbid  Memory - Model  ends ******************** -->

<!-- *********************** Distributed Shared Memory PGAS  starts ********************* -->


<a name="dist-shared-mem-model-pgas"> </a>


<TABLE cellSpacing=0 cellPadding=0  border=0> 
<TBODY>

<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b>Distributed Shared Memory Model-PGAS </b> 
</font> 
</DIV>
</TD> 
</TR> 

<TR>
<TD>

 <P align = "justify"> <span class="content"> 
  

PGAS abbreviates to "Partitioned Global Address Space Programming Model" also called as Distributed Shared 
Memory Model (DSM). PGAS is same as Shared Memory Model, with the addition of being able to make use of data locality.
 It introduces a new concept of affinity. <BR> <BR>

In PGAS model, memory is partitioned and each partition has affinity with a thread and some primitives are provided 
for accessing remote elements. PGAS languages are the ability for the programmer to identify local (private) data and 
global (shared, possibly remote) data. Careful management of local and global data access is typically required to obtain
 good performance.
PGAS models allow for explicit or implicit one-sided data transfers (i.e., put and get operations) to take place through 
reading and writing global variables. This provision reduces the complexity of data management from a programmer's
 perspective by eliminating the need to match send and receive operations and can facilitate the development of 
applications exhibiting fine-grained parallelism or using algorithms that are complex to program under a message-passing 
environment. However, the PGAS abstraction requires programmers to handle 
new challenges 1 (e.g., locating race conditions) and forces them to give up some control over the interaction 
between processing nodes. This loss of control increases the likelihood of a mismatch between the actual execution 
pattern and the one intended by the programmer, which can lead to an underperforming application, or worse, 
an application that does not work as intended. The performance impact of such a mismatch is most apparent in 
cluster environments, where inter-node operations are several orders of magnitude more expensive than local operations.
 For this reason, it is even more critical for PGAS programmers to have access to effective performance analysis tools 
to reap the benefits these models provide. 
<BR> <BR>
Like MPI, applications using the PGAS programming model assume multiple independent CPUs with a communication mechanism 
between them.   However, PGAS makes heavy use of one-sided communication mechanisms that usually have significantly lower 
overhead than two-sided MPI communication. One-sided communication mechanisms allow an initiator to access a remote CPU's
 memory without the explicit involvement of the application running on the remote CPU. Upon receipt of an incoming 
message, the protocol processing engine (e.g., the OS kernel or an intelligent NIC) is provided sufficient information 
so that the receiving application need not be involved in completing the communication. The implementation can be done 
in a number of ways depending on using available OS and hardware features. <BR> <BR>


Unfortunately, tool support for PGAS models has been limited. Existing tools that support MPI are not equipped to
 handle several operation types provided by PGAS models, such as implicit one-sided communications and work-sharing 
constructs. In addition, the variety of PGAS compiler implementation techniques complicates the performance data 
collection process, making it difficult for existing tools to extend support to PGAS models. For these reasons, 
there exists a need for a new performance system capable of handling the challenges associated with PGAS models.
This is one of the most preferred Parallel Programming model these days. Many implementations of PGAS Model 
exists like :</span> </p>

<ul>
<blockquote>
 <P align=justify><span class="content" >
 <li>  	UPC (Unified parallel C) </li>
  <li>  X10 (IBM) </li>
  <li> Co-array Fortran  (CAF) for Fortran</li>
   <li> Titanium for Java </li>
  <li>  Global Arrays </li> 
   <li> Chapel (Cray) </li>
</span> </p>
</blockquote>
</ul>

</span> </p>

<P align = "justify"> <span class="content"> 
  
The current implementations of the PGAS programming model can be divided into library-based and language-based. Library-based implementations typically consist of a set of callable function routines from C, C++, or Fortran. These libraries usually do not require any unique support from compilers, operating systems, or parallel runtime systems. On the other hand, language-based implementations are extensions of standard programming languages, and depend on compiler or translator support and may require support from a parallel runtime
system.

</span> </p>

<DIV align=Left><font size="2"> 
<font size = "2" color ="black" type = "verdana">
     <b>PGAS - Library based Implementations  </b> 
</font> 
</DIV>
 <a name="dist-shared-mem-ga"> </a>
<ul>
<li>     
<P align = "justify"> <span class="content">
 <B> Global Arrays :  </b> Global Arrays : It provides a shared memory view of distributed data structures for a MIMD parallel program. The Global Arrays toolkit implements a shared-memory programming model in which data locality is managed by the programmer. This management is achieved by calls to functions that transfer data between a global address space (a distributed array) and local storage. <BR> <BR>


It allows each process to access logical blocks of physically distributed multidimensional arrays as if they were located in shared memory. The GA programming model is primarily a memory rather than interprocess communication model, as it provides interfaces for data movement between shared and local memory. GA is built upon a low-level message passing system called the Aggregate Remote Memory Copy Interface (ARMCI). GA was developed at Pacific Northwest National Laboratory (PNNL). In this respect, the GA model has similarities to the distributed shared-memory models that provide an explicit acquire/release protocol. However, the GA model acknowledges that remote data is slower to access than local data and allows data locality to be specified by the programmer and hence managed. GA is related to the global address space languages such as UPC, Titanium, and, to a lesser extent, Co-Array Fortran.  <BR> <BR>

In addition, by providing a set of data-parallel operations, GA is also related to data-parallel languages such as HPF  and Data Parallel C. However, the Global Array programming model is implemented as a library that works with most languages used for technical computing and does not rely on compiler technology for achieving parallel efficiency. It also supports a combination of task- and data-parallelism and is available as an extension of the message passing (MPI) model. The GA model exposes to the programmer the hierarchical memory of modern high-performance computer systems , and by recognizing the communication overhead for remote data transfer, it promotes data reuse and locality of reference. Virtually all the scalable architectures possess non-uniform memory access characteristics that reflect their multi-level memory hierarchies. These hierarchies typically comprise processor registers, multiple levels of cache, local memory, and remote memory. Over time, both the number of levels and the cost (in processor cycles) of accessing deeper levels has been increasing. It is important for any scalable programming model to address memory hierarchy since it is critical to the efficient execution of scalable applications. <BR> <BR>

GA allows the programmer to control data distribution and makes the locality information readily available to be exploited for performance optimization. For example, global arrays can be created by 1) allowing the library to determine the array distribution, 2) specifying the decomposition for only one array dimension and allowing the library to determine the others, 3) specifying the distribution block size for all dimensions, or 4) specifying an irregular distribution as a Cartesian product of irregular distributions for each axis. The distribution and locality information is always available through interfaces to query 1) which data portion is held by a given process, 2) which process owns a particular array element, and 3) a list of processes and the blocks of data owned by each process corresponding to a given section of an array. The primary mechanisms provided by GA for accessing data are block copy operations that transfer data between layers of memory hierarchy, namely global memory (distributed array) and local memory. 
 

</span> </p>

   </li>

<a name = "dist-shared-mem-proglib"> </a>
  

<li> 
<P align = "justify"> <span class="content">
 
<B> The SHMEM library : </B> It is a one-sided programming model developed by Cray.  It is a set of communication primitives based on simple underlying get/put functionality, with some additional shared memory-like primitives, such as remote fetch-and-increment and remote atomic swap operations. The SHMEM implementation on the Cray T3 leveraged the hardware and runtime system support for globally addressable memory. The SHMEM library on the Cray T3 had both C and Fortran interfaces, and was used as the underlying data movement layer for implementations of UPC and Co-Array Fortran. Portable implementation of a subset of the SHMEM API called Generalized Portable SHMEM, or GPSHMEM  is also available and this implementation runs on a wide variety of machines and clusters.
</span> </p>
   </li>

   <li> 

<P align = "justify"> <span class="content">
 	<B> The MPI 2.1 standard </B> : It defines an interface and semantics for one-sided communication
operations. MPI allows a process to expose a portion of its address space as a "window" that other processes can manipulate. One-sided operations in MPI are more heavyweight than typical one-sided interfaces, mostly due to the need to allow for portability and to support heterogeneous computing.
</span>
</p>
</li>

</ul>

<HR>

<div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>


<DIV align=Left><font size="2"> 
<font size = "2" color ="black" type = "verdana">
     <b>PGAS - Language Extensions Implementations  </b> 
</font> 
</DIV>

  <a name="dist-shared-mem-upc"> </a>
     
<P align = "justify"> <span class="content">
 <B> UPC :  </b> Unified Parallel C (UPC) is an extension of C for programming multiprocessors with a shared address space. UPC is designed to use message passing techniques to simulate a shared memory multiprocess environment. UPC is also designed to support the Distributed Shared Memory Model, which is in between the Distributed Memory Model and the Shared Memory Model. It has numerous features designed to make parallelisation as simple as possible, whilst also attempting to preserve the efficiency and overall structure of C. The hope is to achieve the balance between the ease of use (of the shared memory model) and the ability to exploit data locality (of the message passing model). It provides a Partitioned Global Address Space for the transfer of data between processes, as well as numerous synchronization and collective functions that enable the control of program flow between parallel threads. <Br> <Br>

UPC is supported on both shared- and distributed-memory systems and presents the programmer with a logically partitioned global address space that is physically distributed across available memory domains. Under UPC, every shared data element has affinity to a distinct processor, and UPC exposes this data locality information to the programmer so that it can be leveraged to enhance performance. Shared data can be accessed through built-in language-level support as well as through explicit one-sided communication operations. Regardless of location, all data in the global address space can be accessed without explicit help from the data's owner.
<BR> <BR>



UPC provides a common syntax and semantics for explicit parallel programming in C, and it directly maps language features to the underlying architecture. UPC is an example of the partitioned shared memory programming model in which shared memory is partitioned among all UPC threads (processes). This partition is formally represented in the programming language. Each thread can access any location in shared memory using the same syntax but the locations in each thread's own partition of shared memory are accessed more quickly. The idea behind UPC is that users should be able to view the underlying machine model as a collection of threads operating in a common global address space. Specifically, each thread can access data resident in:
<BR> <BR>



<ul>
<li>
<P align = "justify"> <span class="content">
the local part of the address space
</span> </p>
</li>

<li>
<P align = "justify"> <span class="content">
the shared part of the address space with affinity to that thread the shared part of the address space with affinity to other threads
</span> </p>
</li>

<li>
<P align = "justify"> <span class="content">
There is no explicit message passing, as UPC features are at a significantly higher-level than MPI.
</span> </p>
</li>

</ul>

<P align = "justify"> <span class="content">
UPC has been gaining interests from academia, industry and government labs. A UPC consortium (www.upc.gwu.edu) has been formed to foster and coordinate UPC development and research activities. Several organizations including academia, vendors, government, and supercomputing centers all over the world are actively involved in UPC research and development. Most of the work is focused on UPC Complier implementations such as GCC-based compiler.

</span> </p>

<a name = "dist-shared-mem-caf"> </a>


<P align = "justify"> <span class="content"> <B> Co-array Fortran (CAF) : </B> 
Co-Array Fortran (CAF) is an extension to Fortran. Co-Array Fortran is a simple syntactic extension to Fortran 95 that converts it into a robust, efficient parallel language. It has the look-and-feel of Fortran and requires Fortran programmers to learn only a few new rules. These new rules are related to two fundamental issues that any parallel programming model must resolve: work distribution and data distribution. <BR> <Br>

CAF supports the SPMD model of computation in which a collection of process images execute asynchronously and share data using one-sided communication through an explicit syntax. Process images interact by reading and writing data objects that are marked as co-arrays. 
CAF is based on Fortran 95 and inherits multi-dimensional arrays. 

The programmer is responsible for synchronization among images using memory barriers and flexible lightweight synchronization primitives that support pair-wise, group, and barrier synchronization. CAF does not require a single (physical) global address space. (see http://www.co-array.org/ for more details).  
CAF differs from the other PGAS languages in that programmers explicitly specify the target image of a remote co-array access. CAF has several synchronization primitives.  <BR> <BR>

Two CAF compiler implementations: one is available on Cray architectures, the other is a multi-platform CAF compiler developed at Rice University. Co-array Fortran supports SPMD parallel programming through a small set of language extensions to Fortran 95. An executing CAF program consists of a static collection of asynchronous process images. Similar to MPI, CAF programs explicitly distribute data and computation. However, CAF belongs to the family of Global Address Space programming languages and provides the abstraction of globally accessible memory for both distributed and shared memory architectures. 
CAF provides co-arrays to efficiently access remote array and scalar data.
</span> </p>

<a name = "dist-shared-mem-titanium"> </a>

<P align = "justify"> <span class="content">
 	<B> Titanium for Java </B> : Titanium is an explicitly-parallel SPMD language based on Java.  It is an object-oriented, strongly-typed language and it provides a Partitioned Global Address Space (PGAS) memory model.   The focus of Titanium language design and implementation is
on providing sequential memory consistency without sacrificing performance.
Titanium supports the creation of complicated data structures and abstractions using the object-oriented class mechanism of Java, augmented with a global address space to allow for the creation of large, distributed shared structures. As Titanium is essentially a superset
of Java, it inherits all the expressiveness, usability and safety properties of that language. In addition, Titanium notably adds a number of features to standard Java that are designed to support high-performance computing. These features are described in detail in the Titanium language reference and include: (1) Flexible and efficient multi-dimensional arrays, (2) Built-in support for multi-dimensional domain calculus, (2)  Locality and sharing reference qualifiers, (3) Explicitly unordered loop iteration,  (4) User-defined immutable classes, (5) Operator-overlading and (6) cross language support. It has garbage collected memory as well as zone-based managed memory for performance. It supports multi-dimensional arrays. Remote memory is accessed using global pointers; the local type qualifier is used to indicate that a pointer points to an object residing in the local demesne (memory), thus compiler optimizations are possible for local references. 

</span>
</p>
 
<BR> 

<a name = "dist-shared-memoryx10" > </a>

<P align = "justify"> <span class="content">
<B> X10  (IBM) </B> : X10 is a modern object-oriented programming language in the PGAS family. The fundamental goal of X10 is to enable scalable, high-performance, high-productivity transformational programming for high-end computers - for traditional numerical computation workloads (such as weather simulation, molecular dynamics, particle transport problems etc) as well as commercial server workloads. X10 is based on state-of-the-art object-oriented programming ideas primarily to take advantage of their proven flexibility and ease-of-use for a wide spectrum of programming problems. X10 takes advantage of several years of research (e.g. in the context of the Java) on how to adapt such languages to the context of high-performance numerical computing. 
<BR> <BR>

X10 introduces a flexible treatment of concurrency, distribution and locality, within an integrated type system. X10 extends the PGAS model to the globally asynchronous, locally synchronous (GALS) model originally developed in hardware and embedded software research. X10 introduces places as an abstraction for a computational context with a locally synchronous view of shared memory. An X10 computation runs over a large collection of places. A computation is divided among a set of places, each of which holds some data and hosts one or more activities that operate on those data. It supports a constrained type system for object-oriented programming, as well as user-defined primitive struct types; globally distributed arrays, and structured and unstructured parallelism. X10 uses the concept of parent and child relationships for activities to prevent the lock stalemate that can occur when two or more processes wait for each other to finish before they can complete.
<BR>  <BR>

X10 may be thought of as (generic) Java less concurrency, arrays and built-in types, plus places, activities, clocks, (distributed, multi-dimensional) arrays and value types. All these changes are motivated by the desire to use the new language for high-end, high-performance, high-productivity computing. The central new concept in X10 is that of a place. A place
may be thought of conceptually as a "virtual shared-memory multi-processor": a computational unit with a finite, though perhaps dynamically varying, number of hardware threads and a bounded amount of shared memory uniformly accessible by all threads. An X10 program is intended to run on a wide range of computers, from uniprocessors to large clusters of parallel processors supporting millions of concurrent operations. An X10 computation acts on data objects through the execution of lightweight threads called activities. X10 has a unified or global address space.
<Br> <BR>

</span>
</p>
 

<a name = "dist-shared-mem-chapel"> </a>
          
<P align = "justify"> <span class="content">
 	<B> Chapel  </B> : Chapel is an emerging parallel programming language whose design and development is being led by Cray Inc. Chapel is serving as a portable parallel programming model that can be used on commodity clusters or desktop multicore systems. Chapel is another parallel programming programming models like MPI.

Chapel supports global-view programming that makes it far easier to write a particular, but common, style of program on distributed-memory systems. The central abstraction supporting global-view parallelism is the concept of a global array. A global array is an entity that can be treated as a whole even though its elements are partitioned across a system's locales. 
Chapel supports programmer control of locality by allowing the programmer to explicitly control the affinity of both tasks
and data to locales.

Chapel supports a multithreaded execution model via high-level abstractions for data parallelism, task parallelism, concurrency, and nested parallelism. Chapel's locale type enables users to specify and reason about the placement of data and tasks on a target architecture in order to tune for locality. Chapel supports global-view data aggregates with user-defined implementations, permitting operations on distributed data structures to be expressed in a natural manner.

</span>
</p>
 


<HR>

<div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>

</TD> 
</TR> 
</TBODY> 
</TABLE> 

<!-- ********************** Distributed Shared Memory - PGAS  ends ******************** -->



<!-- ****************************** Distributed Memory Model Hands-on s Starts ************************* -->


<a name="pgas-hands-on-session-topics"> </a>

<TABLE cellSpacing=0 cellPadding=0  border=0> 
<TBODY>


<TR> 
<TD bgColor = "#cccdd77889"> 

<DIV align=Left><font size="2"> 
<font size = "3" color ="black" type = "verdana">
     <b>Mode-1 :  Multi-Core (PGAS)</b> 
</font> 
</DIV

</TD>
</TR>

<TR>
<TD>
<BR>

 <span class ="content"> <font color ="black"> <Strong>
    Mode 1:   Tuning &amp; Performance of programs on Multi-Core Processors &amp;  
               Distributed Shared Address Space (PGAS) memory Models </font> </strong>
  </span>
		
 <ul>
     
   <li>
   <p align = "Justify")
   <span class = "content">
             Example Programs based on Thread Programming constructs will be made available.
     </span> 
    </p> 
     </li>

    <li> <p align = "Justify") <span class = "content">
            Example Programs based on Thread/OpenMP/MPI/TBB focusing on numerical computations 
          (Numerical Linear Algebra  Dense / Sparse Matrix Computations) will  be discussed.
         </span>  </p>  </li>

    <li> <p align = "Justify") <span class = "content">
          Demonstrate the compiler capabilities  for Numerical Kernels &amp; Benchmarks based on  PGAS Memory Models ( UPC, X10, titanium, Chapel &amp; CAF )
        </span>  </p>  </li>

      <li> <p align = "Justify") <span class = "content">
           Walk-through parallel programs using Pthreads, OpenMP, TBB, Fortran90,
         MPI 2.0, MPI-Pthreads, MPI-OpenMP on Multi-Core Processors and Clusters of Multi-Core Systems
     </span>  </p>  </li>

      <li> <p align = "Justify") <span class = "content">
             Demonstrate the use of Performance tools (Intel Thrread checker, Thread Vtune Analyzer,
             and Open Source Software tools) on Multi-Core Processor Systems.
        </span>  </p>  </li>

     <li> <p align = "Justify") <span class = "content">
             Demonstrate the performance  of Numerical Kernels &amp; Benchmarks based on PGAS Memory              Models such as UPC, X10 (IBM), titanium, Chapel (Cray) &amp; CAF 
        </span>  </p>  </li>

   
     <li> <p align = "Justify") <span class = "content">
             Demonstrate the performance  of Numerical Kernels based on MPI & PGAS Memory Models such
             as UPC.
        </span>  </p>  </li>

    <li> <p align = "Justify") <span class = "content">
         Example Programs based on Thread/OpenMP/MPI/TBB focusing on  non-numerical computations
         (Graph Coloring, Sorting algorithms) will  be discussed.
      </span>  </p>  </li>



   </ul>

  <div align ="right">
  <a href="#top"><img src="./hypack13_images/top.gif" align="right" border="0" width="13" height="13" ></a>
</div>


</TD>
</TR>
</TBODY> 
</TABLE>


<!-- ************************ Distributed Memory Model  Ends ********************* -->


           
</TD></TR></TBODY></TABLE>

</TBODY></TABLE>




</TD></TR></TBODY></TABLE> 


      <TABLE  class=footarea cellSpacing=0 cellPadding=0 border=0 >
        <TBODY>
        <TR>

          <TD class=footertext align=center>
           <A href="http://www.cdac.in" target=_blank><FONT color=blue size=2>
            Centre for Development of Advanced Computing </FONT></A> 
         </TD>

        

        </TR></TBODY></TABLE>


</TD></TR></TBODY></TABLE>

</TD></TR></TBODY></TABLE></BODY></HTML>
